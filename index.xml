<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Me</title>
    <link>https://copuronur.github.io/</link>
      <atom:link href="https://copuronur.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Me</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://copuronur.github.io/media/icon_hu977448f5f7d0285f18cfefcfd5153e92_24079_512x512_fill_lanczos_center_3.png</url>
      <title>Me</title>
      <link>https://copuronur.github.io/</link>
    </image>
    
    <item>
      <title>Example Talk</title>
      <link>https://copuronur.github.io/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Unsupervised Learning</title>
      <link>https://copuronur.github.io/post/deep_unsupervised/</link>
      <pubDate>Fri, 24 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/post/deep_unsupervised/</guid>
      <description>&lt;h1 id=&#34;lecture-1-autoregressive-models&#34;&gt;Lecture 1 (Autoregressive Models)&lt;/h1&gt;
&lt;h2 id=&#34;likelihood-based-models&#34;&gt;Likelihood-based models&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Problems we’d like to solve: Generating data, compressing data, anomaly detection&lt;/li&gt;
&lt;li&gt;Likelihood-based models estimate the data distribution from some samples from the data distribution&lt;/li&gt;
&lt;li&gt;the aim is to estimate the distribution of &lt;strong&gt;complex, high-dimensional data&lt;/strong&gt; with computational and statistical efficiency.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generative-models&#34;&gt;Generative models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Maximum likelihood: given a dataset x(1), …, x(n), find θ by solving the optimization problem.&lt;/p&gt;
   &lt;!-- $\arg\min_\theta \ \mathrm{loss}(\theta, \mathbf{x}^{(1)}, \dotsc, \mathbf{x}^{(n)}) = \frac{1}{n}\sum_{i=1}^n -\log p_\theta(\mathbf{x}^{(i)})$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Carg%5Cmin_%5Ctheta%20%5C%20%5Cmathrm%7Bloss%7D(%5Ctheta%2C%20%5Cmathbf%7Bx%7D%5E%7B(1)%7D%2C%20%5Cdotsc%2C%20%5Cmathbf%7Bx%7D%5E%7B(n)%7D)%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5En%20-%5Clog%20p_%5Ctheta(%5Cmathbf%7Bx%7D%5E%7B(i)%7D)&#34;&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It is equivalent to minimizing KL divergence between the empirical distribution and the model.&lt;/p&gt;
   &lt;!-- $\hat p_\mathrm{data}(\mathbf{x}) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}[\mathbf{x} = \mathbf{x}^{(i)}]$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Chat%20p_%5Cmathrm%7Bdata%7D(%5Cmathbf%7Bx%7D)%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi%3D1%7D%5En%20%5Cmathbf%7B1%7D%5B%5Cmathbf%7Bx%7D%20%3D%20%5Cmathbf%7Bx%7D%5E%7B(i)%7D%5D&#34;&gt;
   &lt;!-- $\mathrm{KL}(\hat p_\mathrm{data} \,\|\, p_\theta) = \mathbb{E}_{\mathbf{x}\sim \hat p_\mathrm{data}}[-\log p_\theta(\mathbf{x})] - H(\hat p_\mathrm{data})$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Cmathrm%7BKL%7D(%5Chat%20p_%5Cmathrm%7Bdata%7D%20%5C%2C%5C%7C%5C%2C%20p_%5Ctheta)%20%3D%20%5Cmathbb%7BE%7D_%7B%5Cmathbf%7Bx%7D%5Csim%20%5Chat%20p_%5Cmathrm%7Bdata%7D%7D%5B-%5Clog%20p_%5Ctheta(%5Cmathbf%7Bx%7D)%5D%20-%20H(%5Chat%20p_%5Cmathrm%7Bdata%7D)&#34;&gt;
&lt;p&gt;&lt;strong&gt;How do we solve this optimization problem?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stochastic Gradient descent
   &lt;!-- $\arg\min_\theta \mathbb{E}{\mathbf{x} \sim \hat p\mathrm{data}}[-\log p_\theta(\mathbf{x})]$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Carg%5Cmin_%5Ctheta%20%5Cmathbb%7BE%7D%7B%5Cmathbf%7Bx%7D%20%5Csim%20%5Chat%20p%5Cmathrm%7Bdata%7D%7D%5B-%5Clog%20p_%5Ctheta(%5Cmathbf%7Bx%7D)%5D&#34;&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Why maximum likelihood + SGD?&lt;/strong&gt; It works with large datasets and is compatible with neural networks.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;designing-the-model&#34;&gt;Designing The Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The key requirement for maximum likelihood + SGD: efficiently compute log p(x) and its gradient.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;pθ —&amp;gt; deep neural network&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
 &lt;!-- $for\ all\ \theta,\quad \sum_\mathbf{x} p_\theta(\mathbf{x}) = 1 \quad\text{and}\quad p_\theta(\mathbf{x}) \geq 0 \quad\ for\ all\ \mathbf{x}$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=for%5C%20all%5C%20%5Ctheta%2C%5Cquad%20%5Csum_%5Cmathbf%7Bx%7D%20p_%5Ctheta(%5Cmathbf%7Bx%7D)%20%3D%201%20%5Cquad%5Ctext%7Band%7D%5Cquad%20p_%5Ctheta(%5Cmathbf%7Bx%7D)%20%5Cgeq%200%20%5Cquad%5C%20for%5C%20all%5C%20%5Cmathbf%7Bx%7D&#34;&gt;
&lt;h3 id=&#34;autoregressive-model&#34;&gt;Autoregressive model&lt;/h3&gt;
&lt;p&gt;An expressive Bayes net structure with neural network conditional distributions yields an expressive model for p(x) with tractable maximum likelihood training.&lt;/p&gt;
 &lt;!-- $\log p_\theta(\mathbf{x}) = \sum_{i} \log p_\theta(x_i \,|\, \mathrm{parents}(x_i))$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Clog%20p_%5Ctheta(%5Cmathbf%7Bx%7D)%20%3D%20%5Csum_%7Bi%7D%20%5Clog%20p_%5Ctheta(x_i%20%5C%2C%7C%5C%2C%20%5Cmathrm%7Bparents%7D(x_i))&#34;&gt;
&lt;h3 id=&#34;rnn-autoregressive-models---char-rnn&#34;&gt;RNN autoregressive models - char-rnn&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;masking-based-autoregressive-models&#34;&gt;Masking-based autoregressive models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Masked Autoencoder for Distribution Estimation (MADE)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%201.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;masked-temporal-1d-convolution-wavenet&#34;&gt;Masked Temporal (1D) Convolution (WaveNet)&lt;/h3&gt;
&lt;p&gt;Improved receptive field: dilated convolution, with exponential dilation. Better expressivity: Gated Residual blocks, Skip connections.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://procedural-generation.isaackarth.com/tumblr_files/tumblr_od90sk1vkL1uo5d9jo1_640.gif&#34; alt=&#34;https://procedural-generation.isaackarth.com/tumblr_files/tumblr_od90sk1vkL1uo5d9jo1_640.gif&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://haydensansum.github.io/CS205-Waveforms/imgs/wavenet_gate.png&#34; alt=&#34;https://haydensansum.github.io/CS205-Waveforms/imgs/wavenet_gate.png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;masked-spatial-2d-convolution---pixelcnn&#34;&gt;Masked Spatial (2D) Convolution - PixelCNN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Images can be flatten into 1D vectors, but they are fundamentally 2D.&lt;/li&gt;
&lt;li&gt;We can use a masked variant of ConvNet to exploit this knowledge.&lt;/li&gt;
&lt;li&gt;First, we impose an autoregressive ordering on 2D images:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%202.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PixelCNN&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PixelCNN-style masking has one problem: blind spot in the receptive field.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%203.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;masked-attention--convolution&#34;&gt;Masked Attention + Convolution&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%204.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;neural-autoregressive-models-the-good&#34;&gt;Neural autoregressive models: the good&lt;/h2&gt;
&lt;p&gt;Best in class modeling performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;expressivity - autoregressive factorization is general.&lt;/li&gt;
&lt;li&gt;generalization - meaningful parameter sharing has good inductive bias.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;masked-autoregressive-models-the-bad&#34;&gt;Masked autoregressive models: the bad&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Sampling each pixel (1 forward pass)&lt;/p&gt;
&lt;h3 id=&#34;speedup-by-breaking-the-autoregressive-pattern&#34;&gt;Speedup by breaking the autoregressive pattern&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;O(d) -&amp;gt; O(log(d)) by parallelizing within groups {2, 3, 4}.&lt;/li&gt;
&lt;li&gt;Cannot capture dependencies within each group: this is a fine assumption if all pixels in one group are conditionally independent.
&lt;ul&gt;
&lt;li&gt;Most often they are not, then you trade expressivity for sampling speed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%205.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;natural-image-manipulation-for-autoregressive-models-using-fisher-scores&#34;&gt;Natural Image Manipulation for Autoregressive Models using Fisher Scores&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Main challenge:
&lt;ul&gt;
&lt;li&gt;How to get a latent representation from PixelCNN?&lt;/li&gt;
&lt;li&gt;Why hard? The random input happens on a per-pixel sample basis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Proposed solution
&lt;ul&gt;
&lt;li&gt;Use Fisher score&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%206.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%207.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;lecture-2-flow-models&#34;&gt;Lecture 2 (Flow Models)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;How to fit a density $p_Q(x)$ model with continuous $x \in R^n$&lt;/li&gt;
&lt;li&gt;What do we want from this model?
&lt;ul&gt;
&lt;li&gt;Good fit to the training data (really, the underlying distribution!)&lt;/li&gt;
&lt;li&gt;For new &lt;em&gt;x&lt;/em&gt;, the ability to evaluate $p_\theta (x)$&lt;/li&gt;
&lt;li&gt;Ability to sample from $p_\theta (x)$&lt;/li&gt;
&lt;li&gt;And, ideally, a latent representation that’s meaningful&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-to-fit-a-density-model&#34;&gt;How to fit a density model?&lt;/h2&gt;
&lt;h3 id=&#34;option-1-mixture-of-gaussians&#34;&gt;Option 1: Mixture of Gaussians&lt;/h3&gt;
&lt;p&gt;Parameters: means and variances of components, mixture weights&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%208.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;!-- $p_\theta(x) = \sum_{i=1}^k \pi_i \mathcal{N}(x; \mu_i, \sigma_i^2)$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=p_%5Ctheta(x)%20%3D%20%5Csum_%7Bi%3D1%7D%5Ek%20%5Cpi_i%20%5Cmathcal%7BN%7D(x%3B%20%5Cmu_i%2C%20%5Csigma_i%5E2)&#34;&gt;
&lt;!-- $\arg\min_\theta \mathbb{E}_x [ -\log p_\theta (x) ]$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Carg%5Cmin_%5Ctheta%20%5Cmathbb%7BE%7D_x%20%5B%20-%5Clog%20p_%5Ctheta%20(x)%20%5D&#34;&gt;
&lt;h3 id=&#34;option-2-general-density-model&#34;&gt;Option 2: General Density Model&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%209.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to ensure proper distribution?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2010.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How to sample?&lt;/li&gt;
&lt;li&gt;Latent representation?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;flows-main-idea&#34;&gt;Flows: Main Idea&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2011.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;flows-training&#34;&gt;Flows: Training&lt;/h2&gt;
&lt;h3 id=&#34;change-of-variable&#34;&gt;Change of Variable&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2012.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Note: requires&lt;!-- $f_\theta$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=f_%5Ctheta&#34;&gt; invertible &amp;amp; differentiable&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2013.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;assuming we have an expression for  &lt;!-- $pz$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=pz&#34;&gt;, this can be optimized with Stochastic Gradient Descent&lt;/p&gt;
&lt;h2 id=&#34;flows-sampling&#34;&gt;Flows: Sampling&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2014.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;2-d-autoregressive-flow&#34;&gt;2-D Autoregressive Flow&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2015.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;2-d-autoregressive-flow-face&#34;&gt;2-D Autoregressive Flow: Face&lt;/h3&gt;
&lt;p&gt;Architecture:
Base distribution: Uniform[0,1]^2
x1: mixture of 5 Gaussians
x2: mixture of 5 Gaussians, conditioned on x1&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2016.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;!-- $%x_1 &amp;\sim p_\theta(x_1) \\%x_2 &amp;\sim p_\theta(x_2 | x_1) \\%x_3 &amp;\sim p_\theta(x_3 | x_1, x_2) \\x_1 &amp;= f_\theta^{-1}(z_1) \\x_2 &amp;= f_\theta^{-1}(z_2; x_1) \\x_3 &amp;= f_\theta^{-1}(z_3; x_1, x_2) \\$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%25x_1%20%26%5Csim%20p_%5Ctheta(x_1)%20%5C%5C%25x_2%20%26%5Csim%20p_%5Ctheta(x_2%20%7C%20x_1)%20%5C%5C%25x_3%20%26%5Csim%20p_%5Ctheta(x_3%20%7C%20x_1%2C%20x_2)%20%5C%5Cx_1%20%26%3D%20f_%5Ctheta%5E%7B-1%7D(z_1)%20%5C%5Cx_2%20%26%3D%20f_%5Ctheta%5E%7B-1%7D(z_2%3B%20x_1)%20%5C%5Cx_3%20%26%3D%20f_%5Ctheta%5E%7B-1%7D(z_3%3B%20x_1%2C%20x_2)%20%5C%5C&#34;&gt;
&lt;h3 id=&#34;autoregressive-flows&#34;&gt;Autoregressive flows&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;How to fit autoregressive flows?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Map &lt;strong&gt;x&lt;/strong&gt; to &lt;strong&gt;z&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Fully parallelizable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Notice&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;x → z&lt;/strong&gt; has the same structure as the &lt;strong&gt;log likelihood&lt;/strong&gt; computation of an autoregressive model&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;z → x&lt;/strong&gt; has the same structure as the &lt;strong&gt;sampling&lt;/strong&gt; procedure of an autoregressive model&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2017.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inverse-autoregressive-flows&#34;&gt;Inverse autoregressive flows&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The inverse of an autoregressive flow is also a flow, called the &lt;strong&gt;inverse autoregressive flow (IAF)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;x → z&lt;/strong&gt; has the same structure as the &lt;strong&gt;sampling&lt;/strong&gt; in an autoregressive model&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;z → x&lt;/strong&gt; has the same structure as &lt;strong&gt;log likelihood&lt;/strong&gt; computation of an autoregressive model. So, &lt;strong&gt;IAF sampling is fast&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2018.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;af-vs-iaf&#34;&gt;AF vs IAF&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Autoregressive flow
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; evaluation of p(x) for arbitrary x&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Slow&lt;/strong&gt; sampling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Inverse autoregressive flow
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Slow&lt;/strong&gt; evaluation of p(x) for arbitrary x, so training directly by maximum likelihood is slow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; sampling&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast&lt;/strong&gt; evaluation of p(x) if x is a sample&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;There are models (Parallel WaveNet, IAF-VAE) that exploit IAF’s fast sampling.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;change-of-many-variables&#34;&gt;Change of MANY variables&lt;/h3&gt;
&lt;p&gt;For &lt;!-- $z \sim p(z)$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=z%20%5Csim%20p(z)&#34;&gt;, the sampling process f-1 linearly transforms a small cube &lt;!-- $dz$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=dz&#34;&gt;  to a small parallelepiped &lt;!-- $dx$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=dx&#34;&gt;. Probability is conserved:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2019.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Intuition&lt;/strong&gt;: x is likely if it maps to a “large” region in z space&lt;/p&gt;
&lt;h2 id=&#34;high--dimensional-flow-models-training&#34;&gt;High- Dimensional Flow models: training&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Change-of-variables formula&lt;/strong&gt; lets us compute the density over x:&lt;/p&gt;
&lt;!-- $p_\theta(\mathbf{x}) = p(f_\theta(\mathbf{x})) \left| \frac{\partial f_\theta(\mathbf{x})}{\partial \mathbf{x}} \right|$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=p_%5Ctheta(%5Cmathbf%7Bx%7D)%20%3D%20p(f_%5Ctheta(%5Cmathbf%7Bx%7D))%20%5Cleft%7C%20%5Cfrac%7B%5Cpartial%20f_%5Ctheta(%5Cmathbf%7Bx%7D)%7D%7B%5Cpartial%20%5Cmathbf%7Bx%7D%7D%20%5Cright%7C&#34;&gt;
&lt;p&gt;Train with maximum likelihood:&lt;/p&gt;
&lt;!-- $\arg\min_\theta \mathbb{E}_\mathbf{x} \left[ -\log p_\theta(\mathbf{x}) \right] = \mathbb{E}_\mathbf{x} \left[ -\log p(f_\theta(\mathbf{x})) - \log \mathrm{det} \left| \frac{\partial f_\theta(\mathbf{x})}{\partial \mathbf{x}} \right| \right]$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=%5Carg%5Cmin_%5Ctheta%20%5Cmathbb%7BE%7D_%5Cmathbf%7Bx%7D%20%5Cleft%5B%20-%5Clog%20p_%5Ctheta(%5Cmathbf%7Bx%7D)%20%5Cright%5D%20%3D%20%5Cmathbb%7BE%7D_%5Cmathbf%7Bx%7D%20%5Cleft%5B%20-%5Clog%20p(f_%5Ctheta(%5Cmathbf%7Bx%7D))%20-%20%5Clog%20%5Cmathrm%7Bdet%7D%20%5Cleft%7C%20%5Cfrac%7B%5Cpartial%20f_%5Ctheta(%5Cmathbf%7Bx%7D)%7D%7B%5Cpartial%20%5Cmathbf%7Bx%7D%7D%20%5Cright%7C%20%5Cright%5D&#34;&gt;
&lt;p&gt;&lt;strong&gt;New key requirement&lt;/strong&gt;: the Jacobian determinant must be easy to calculate and differentiate!&lt;/p&gt;
&lt;h2 id=&#34;nicerealnvp&#34;&gt;NICE/RealNVP&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Split variables in half: &lt;!-- $x_{1:d/2}, x_{d/2+1:d}$ --&gt; &lt;img style=&#34;transform: translateY(0.1em); background: white;&#34; src=&#34;https://render.githubusercontent.com/render/math?math=x_%7B1%3Ad%2F2%7D%2C%20x_%7Bd%2F2%2B1%3Ad%7D&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2020.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invertible! Note that $sθ$ and $t_θ$ can be arbitrary neural nets with &lt;strong&gt;no restrictions&lt;/strong&gt;.
&lt;ul&gt;
&lt;li&gt;Think of them as &lt;strong&gt;data-parameterized elementwise flows&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Deep%20Unsupervised%20Learning%208ba1b8b456a243c485efcb0cf0ea9371/Untitled%2021.png&#34; alt=&#34;Untitled&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Comparative Study of Forecasting Models for COVID-19 Outbreak in Turkey</title>
      <link>https://copuronur.github.io/publication/conference-paper/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/publication/conference-paper/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Big Data computing</title>
      <link>https://copuronur.github.io/post/big_data_computing/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/post/big_data_computing/</guid>
      <description>&lt;h2 id=&#34;-------------------map-reduce-------------------&#34;&gt;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash; MAP REDUCE &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&lt;/h2&gt;
&lt;h2 id=&#34;distributed-file-system-dfs&#34;&gt;Distributed File System (DFS)&lt;/h2&gt;
&lt;p&gt;Modern data-mining applications, often called “big-data” analysis, require us to manage immense amounts of data quickly. The key factor of making fast computation is parallelization and this is done via computer clusters. To exploit cluster computing, files must look and behave somewhat differently from the conventional file systems found on single computers. This new file system is called Distributed File System (DFS).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DFS is suitable for enormous, possibly a terabyte in size. If you have only small files, there is no point using a DFS for them.&lt;/li&gt;
&lt;li&gt;Files are rarely updated. Rather, they are read as data for some calculation, and possibly additional data is appended to files from time to time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;One problem in parallel computing is the machine failures. If you have a large computing clusters, you are likely to observe frequent machine failures. To overcome this challenge, Files are dived into &lt;em&gt;chunks&lt;/em&gt; and each &lt;em&gt;chunk&lt;/em&gt; is replicated in different nodes (&lt;em&gt;chunk servers&lt;/em&gt;) of the cluster. Moreover, the nodes holding copies of one chunk should be located on different racks, so we don’t lose all copies due to a rack failure. In the figure bellow, you can see the diagram of a distributed file system. Note that the chunk servers also serve as compute servers.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/dfsfigure.PNG&#34; alt=&#34;DFS structure(chunks and chunk servers)&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The two other components of DFS (which are not shown in figure) are &lt;em&gt;Master Node&lt;/em&gt; and &lt;em&gt;Client library&lt;/em&gt;. Master node stores meta data about where files are stored and Client library talks to master to find chunk servers. The other problem in big data computing is moving data around for different computations is computationally expensive. The way to handle this problem is bring	computation close	to the	data. &lt;strong&gt;MapReduce&lt;/strong&gt; is the programming model introduced to handle these problems and &lt;strong&gt;DFS&lt;/strong&gt; is the Storage Infrastructure - File system associated with this programming model.&lt;/p&gt;
&lt;h2 id=&#34;mapreduce-implementation-centralized&#34;&gt;MapReduce Implementation (centralized)&lt;/h2&gt;
&lt;p&gt;Implementation of MapReduce requires the programmer to write two functions, called &lt;em&gt;Map&lt;/em&gt; and &lt;em&gt;Reduce&lt;/em&gt;. In brief, a MapReduce
computation executes as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Some number of Map tasks each are given one or more chunks from a DFS. These Map tasks turn the chunk into a sequence of &lt;em&gt;key-value&lt;/em&gt; pairs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The key-value pairs from each Map task are collected by a &lt;em&gt;master controller&lt;/em&gt; and sorted by key. The keys are divided among all the Reduce tasks, so all key-value pairs with the same key wind up at the same Reduce task.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The Reduce tasks work on one key at a time, and combine all the values associated with that key in some way.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the diagram bellow, you can see a MapReduce implementation for the word count task. Note that this scheme shows how MapReduce works in a centralized system.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/Capture.PNG&#34; alt=&#34;Map reduce diagram centralized&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;mapreduce-implementation-parallel&#34;&gt;MapReduce Implementation (Parallel)&lt;/h2&gt;
&lt;p&gt;However we are more interested in MapReduce in a computer cluster. In a computer cluster Map and Reduce tasks are running in parallel on multiple nodes. As we mentioned before, same data chunks can appear in different nodes and different Map tasks maybe processing same data chunks. But for the reduce tasks, we want put all key-value pairs with same key to the same reduce task. Here we introduce the &lt;em&gt;Partitioning Function&lt;/em&gt; which is just a hash function responsible from this operation. In the figure bellow, you can see the MapReduce reduce diagram in parallel.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/mapreduceparallel.PNG&#34; alt=&#34;Map reduce diagram in computer cluster&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;mapreduce-environment-duties&#34;&gt;MapReduce environment duties:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Partitioning the input data.&lt;/li&gt;
&lt;li&gt;Scheduling the program&amp;rsquo;s execution across a set of machines.&lt;/li&gt;
&lt;li&gt;Performing the &lt;em&gt;group by key&lt;/em&gt; step.&lt;/li&gt;
&lt;li&gt;Handling machine failures.&lt;/li&gt;
&lt;li&gt;Managing required intermachine communication.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-flow&#34;&gt;Data Flow&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Input and final output are stored on the  DFS.
&lt;ul&gt;
&lt;li&gt;Scheduler tries to schedule map tasks to each chunk server which contains corresponding data chunk.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Intermediate results are stored on local file system of Map and Reduce workers.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;details-of-mapreduce-execution&#34;&gt;Details of MapReduce Execution&lt;/h3&gt;
&lt;p&gt;The figure bellow offers an outline of how process, tasks and files interact. Taking advantage of a client library provided by a MapReduce system, the user program forks a &lt;em&gt;Master Controller&lt;/em&gt; process and some number of &lt;em&gt;Map workers&lt;/em&gt; and &lt;em&gt;Reduce workers&lt;/em&gt;. Note that a worker handles either Map tasks or Reduce tasks.&lt;/p&gt;
&lt;p&gt;The Master has many responsibilities. One is to create some number of Map tasks and some number of Reduce tasks, these numbers being selected by the user program. These tasks will be assigned to Worker processes by the Master. It is reasonable to create one Map task for every chunk of the input file(s), but we may wish to create fewer Reduce tasks. The reason for limiting the number of Reduce tasks is that it is necessary for each Map task to create an intermediate file for each Reduce task, and if there are too many Reduce tasks the number of intermediate files explodes. The Master keeps track of the status of each Map and Reduce task (idle, executing at a particular Worker, or completed). A Worker process reports to the Master when it finishes a task, and a new task is scheduled by the Master for that Worker process.&lt;/p&gt;
&lt;p&gt;Each Map task is assigned one or more chunks of the input file(s) and executes on it the code written by the user. The Map task creates a file for each Reduce task on the local disk of the Worker that executes the Map task. The Master is informed of the location and sizes of each of these files, and the Reduce task for which each is destined. When a Reduce task is assigned by the Master to a Worker process, that task is given all the files that form its input. The Reduce task executes code written by the user and writes its output to a file that is part of the surrounding distributed file system.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/mapreducedetailed.PNG&#34; alt=&#34;Map reduce execution&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;dealing-with-failures&#34;&gt;Dealing With Failures&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Map worker failure.
&lt;ul&gt;
&lt;li&gt;Map tasks completed or in-progress at worker are rest to idle.&lt;/li&gt;
&lt;li&gt;Reduce workers are notified when task is rescheduled on another worker.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reduce worker failure.
&lt;ul&gt;
&lt;li&gt;Only in-progress tasks are reset to idle.&lt;/li&gt;
&lt;li&gt;Idle Reduce tasks restarted on other worker(s).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Master failure.
&lt;ul&gt;
&lt;li&gt;Map reduce task is aborted and client notified.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;refinements&#34;&gt;Refinements&lt;/h3&gt;
&lt;h4 id=&#34;combiners&#34;&gt;Combiners&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Often a Map task will produce many key-value pairs with same key. We can save time by pre-aggregating values with same key in the mapper.
&lt;ul&gt;
&lt;li&gt;combine(k, list(v1)) -&amp;gt; v2.&lt;/li&gt;
&lt;li&gt;Combiner	is	usually	same as	the	reduce	function.&lt;/li&gt;
&lt;li&gt;Works	only	if	reduce function	is	commutative	and	associative.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;partition-function&#34;&gt;Partition Function&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Want to control how keys get partitioned.&lt;/li&gt;
&lt;li&gt;System uses a default Partition function:
&lt;ul&gt;
&lt;li&gt;hash(key) mod R.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sometimes useful to override the hash function.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;algorithms-using-mapreduce&#34;&gt;Algorithms Using MapReduce&lt;/h2&gt;
&lt;p&gt;The original purpose for which the Google implementation of MapReduce was created was to execute very large matrix-vector multiplications as are needed in the calculation of PageRank.&lt;/p&gt;
&lt;h3 id=&#34;matrix-vector-multiplication-by-mapreduce&#34;&gt;Matrix-Vector Multiplication by MapReduce&lt;/h3&gt;
&lt;p&gt;Suppose we have an n x n matrix M, whose element in row i and column j will be denoted m&lt;sub&gt;ij&lt;/sub&gt; . Suppose we also have a vector v of length n, whose jth element is v&lt;sub&gt;j&lt;/sub&gt; .&lt;/p&gt;
&lt;h4 id=&#34;the-map-function&#34;&gt;The Map function&lt;/h4&gt;
&lt;p&gt;Each Map task will operate on a chunk of the matrix M. From each matrix element m&lt;sub&gt;ij&lt;/sub&gt; it produces the key-value pair (i,m&lt;sub&gt;ij&lt;/sub&gt;v&lt;sub&gt;j&lt;/sub&gt;). Thus, all terms of the sum that make up the component x&lt;sub&gt;i&lt;/sub&gt; of the matrix-vector product will get the same key, i.&lt;/p&gt;
&lt;h4 id=&#34;the-reduce-function&#34;&gt;The Reduce function&lt;/h4&gt;
&lt;p&gt;The Reduce function simply sums all the values associated with a given key i. The result will be a pair (i, x&lt;sub&gt;i&lt;/sub&gt;).&lt;/p&gt;
&lt;p&gt;Note that parallelization of matrix multiplication is very crucial at neural net computations.&lt;/p&gt;
&lt;h3 id=&#34;natural-join-by-mapreduce&#34;&gt;Natural Join by MapReduce&lt;/h3&gt;
&lt;p&gt;Natural join is a frequently used operation in relational database system and parallelization of this operation saves enormous computing time. In the figure bellow yo can see the illustration of Natural Join.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/join.PNG&#34; alt=&#34;Natural Join&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a hash function h from B-values to 1..k&lt;/li&gt;
&lt;li&gt;A map process turns:
&lt;ul&gt;
&lt;li&gt;each input tuple R(a,b) into key-value pair (b, (a,R)).&lt;/li&gt;
&lt;li&gt;each input tuple S(b,c) into key-value pair (b, (c,S)).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map process send each key-value pair with key b to Reduce process h(b).&lt;/li&gt;
&lt;li&gt;Each reduce process matches all the pairs (b, (a,R)) with all (b, (c,S)) and outputs (a,b,c)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cost-measures-for-mapreduce-algorithms&#34;&gt;Cost Measures for MapReduce Algorithms&lt;/h2&gt;
&lt;h3 id=&#34;communication-cost&#34;&gt;Communication Cost&lt;/h3&gt;
&lt;p&gt;input file size + 2x(sum of the sizes of all files passed from Map process to Reduce process) + the sum of the output sizes of the reduce process.&lt;/p&gt;
&lt;h3 id=&#34;elapsed-communication-cost&#34;&gt;Elapsed Communication Cost&lt;/h3&gt;
&lt;p&gt;sum of the largest input  + output for any map process + output for any map process&lt;/p&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://web.stanford.edu/class/cs246/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://web.stanford.edu/class/cs246/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.mmds.org/#ver21&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.mmds.org/#ver21&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;-----finding-simmilar-documnets-----&#34;&gt;&amp;mdash;- FINDING SIMMILAR DOCUMNETS &amp;mdash;-&lt;/h2&gt;
&lt;h2 id=&#34;shingling-of-documents&#34;&gt;Shingling of Documents&lt;/h2&gt;
&lt;p&gt;The most effective way to represent documents as sets, for the purpose of identifying lexically similar documents is to construct from the document the set of short strings that appear within it.&lt;/p&gt;
&lt;h3 id=&#34;k-shingles-or-k-gram&#34;&gt;k-Shingles or k-gram&lt;/h3&gt;
&lt;p&gt;A document is a string of characters. Define a k-shingle for a document to be any substring of length k found within the document. Then, we may associate with each document the set of k-shingles that appear one or more times within that document. Instead of using substrings directly as shingles, we can pick a hash function that maps strings of length k to some number of buckets and treat the resulting bucket number as the shingle. The set representing a document is then the set of integers that are bucket numbers of one or more k-shingles that appear in the document. The result of hashing shingles also called &lt;em&gt;tokens&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;similarity-preserving-summaries-of-sets&#34;&gt;Similarity-Preserving Summaries of Sets&lt;/h2&gt;
&lt;h3 id=&#34;signatures&#34;&gt;Signatures&lt;/h3&gt;
&lt;p&gt;Sets of shingles are large. Even if we hash them to four bytes each, the space needed to store a set is still roughly four times the space taken by the document. If we have millions of documents, it may well not be possible to store all the shingle-sets in main memory.&lt;/p&gt;
&lt;p&gt;Our goal in this section is to replace large sets by much smaller representations called “signatures.” The important property we need for signatures is
that we can compare the signatures of two sets and estimate the Jaccard similarity of the underlying sets from the signatures alone.&lt;/p&gt;
&lt;h3 id=&#34;minhashing&#34;&gt;Minhashing&lt;/h3&gt;
&lt;p&gt;The signatures we desire to construct for sets are composed of the results of a large number of calculations, say several hundred, each of which is a “minhash” of the characteristic matrix. In this section, we shall learn how a minhash is computed in principle, and in later sections we shall see how a good approximation to the minhash is computed in practice.&lt;/p&gt;
&lt;p&gt;To minhash a set represented by a column of the characteristic matrix, pick a permutation of the rows. The minhash value of any column is the number of the first row, in the permuted order, in which the column has a 1. In the table bellow, you can see an example of minhash table with size 3. The input matrix is a matrix with binary input which has documents in the columns and shingles (tokens) in the rows and this input matrix I, has I&lt;sub&gt;ij&lt;/sub&gt; =1, if document j contains token i. To calculate the minhash matrix, first we generate 3 different permutation of rows. Lets check the blue permutation. the first row in the blue permutation refers to the sixth row in the input matrix. In the sixth row we see that columns 1 and 3 has inputs 1, so we put the permutation row number (1 in this case) to the first and third columns of the signature vector. the second row in the blue permutation  refers to the fourth row in the input matrix. In the fourth row we see that columns 2 and 4 has inputs 1, so we put the permutation row number (2 in this case) to the second and fourth columns of the signature vector. As we filled all columns for the blue permutation, we can proceed to other permutations and fill the column values in the same manner.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/minhash.PNG&#34; alt=&#34;Example of Minhashing&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;minhashing-and-jaccard-similarity&#34;&gt;Minhashing and Jaccard Similarity&lt;/h3&gt;
&lt;p&gt;There is a remarkable connection between minhashing and Jaccard similarity of the sets that are minhashed.&lt;/p&gt;
&lt;p&gt;The probability that the minhash function for a random permutation of rows produces the same value for two sets equals the Jaccard similarity of those sets.&lt;/p&gt;
&lt;h3 id=&#34;computation-of-minhas-permutations&#34;&gt;Computation of Minhas Permutations&lt;/h3&gt;
&lt;p&gt;It is not feasible to permute a large characteristic matrix explicitly. Even picking a random permutation of millions or billions of rows is time-consuming, and the necessary sorting of the rows would take even more time.&lt;/p&gt;
&lt;p&gt;Fortunately, it is possible to simulate the effect of a random permutation by a random hash function that maps row numbers to as many buckets as there are rows. A hash function that maps integers 0, 1, . . . , k −1 to bucket numbers 0 through k−1 typically will map some pairs of integers to the same bucket and leave other buckets unfilled. However, the difference is unimportant as long as k is large and there are not too many collisions. We can maintain the fiction that our hash function h “permutes” row r to position h(r) in the permuted order. Thus, instead of picking n random permutations of rows, we pick n randomly chosen hash functions h1, h2, . . . , hn on the rows. We construct the signature matrix by considering each row in their given order.&lt;/p&gt;
&lt;h2 id=&#34;locality-sensitive-hashing-lsh&#34;&gt;Locality Sensitive Hashing (LSH)&lt;/h2&gt;
&lt;p&gt;The general Idea of LSH is generating a small list of candidate pairs (pairs of elements whose similarity must be evaluated) from the collection of all elements. This is done via “hashing” items several times, in such a way that similar items are more likely to be hashed to the same bucket than dissimilar items are. We then consider any pair that hashed to the same bucket for any of the hashings to be a candidate pair. We check only the candidate pairs for similarity.&lt;/p&gt;
&lt;h3 id=&#34;lsh-for-minhash-signatures&#34;&gt;LSH for Minhash Signatures&lt;/h3&gt;
&lt;p&gt;Even though we can use minhashing to compress large documents into small signatures and preserve the expected similarity of any pair of documents, it still may be impossible to find the pairs with greatest similarity efficiently. The reason is that the number of pairs of documents may be too large, even if there are not too many documents. So we refer to the idea of LSH we mentioned above.&lt;/p&gt;
&lt;p&gt;If we have minhash signatures for the items, an effective way to choose the hashings is to divide the signature matrix into b bands consisting of r rows each. For each band, there is a hash function that takes vectors of r integers (the portion of one column within that band) and hashes them to some large number of buckets. We can use the same hash function for all the bands, but we use a separate bucket array for each band, so columns with the same vector in different bands will not hash to the same bucket. In the figure bellow, you can see hash table for a single band in a signature matrix.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/lsh.PNG&#34; alt=&#34;Example of LSH for minhash&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;analysis-of-the-banding-technique&#34;&gt;Analysis of the Banding Technique&lt;/h3&gt;
&lt;p&gt;Suppose we use b bands of r rows each, and suppose that a particular pair of documents have Jaccard similarity s. Recall that the probability the minhash signatures for these documents agree in any one particular row of the signature matrix is s. We can calculate the probability that these documents (or rather their signatures) become a candidate pair as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The probability that the signatures agree in all rows of one particular band is &lt;em&gt;s&lt;/em&gt;&lt;sup&gt;&lt;em&gt;r&lt;/em&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;li&gt;The probability that the signatures disagree in at least one row of a particular band is 1- &lt;em&gt;s&lt;/em&gt;&lt;sup&gt;&lt;em&gt;r&lt;/em&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;li&gt;The probability that the signatures disagree in at least one row of each of the bands is (1- &lt;em&gt;s&lt;/em&gt;&lt;sup&gt;&lt;em&gt;r&lt;/em&gt;&lt;/sup&gt;)&lt;sup&gt;&lt;em&gt;b&lt;/em&gt;&lt;/sup&gt; (also the probability of false negatives for s &amp;gt; threshold).&lt;/li&gt;
&lt;li&gt;The probability that the signatures agree in all the rows of at least one band, and therefore become a candidate pair, is 1- (1- &lt;em&gt;s&lt;/em&gt;&lt;sup&gt;&lt;em&gt;r&lt;/em&gt;&lt;/sup&gt;)&lt;sup&gt;&lt;em&gt;b&lt;/em&gt;&lt;/sup&gt;. (also the probability of false positives for s &amp;lt; threshold).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It may not be obvious, but regardless of the chosen constants b and r, this function has the form of an S-curve, as suggested in the figure bellow and an approximation for the threshold is (&lt;em&gt;1/b&lt;/em&gt;)&lt;sup&gt;&lt;em&gt;1/r&lt;/em&gt;&lt;/sup&gt;. If you want a high recall value, it is better to have high &lt;em&gt;r&lt;/em&gt; and low 0&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/lshrb.PNG&#34; alt=&#34;LSH r and b&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;the-theory-of-locality-sensitive-functions&#34;&gt;The Theory of Locality-Sensitive Functions&lt;/h2&gt;
&lt;p&gt;Now, we shall explore other families of functions, besides the minhash functions, that can serve to produce candidate pairs efficiently. These functions can apply to the space of sets and the Jaccard distance, or to another space and/or another distance measure. There are three conditions that we need for a family of functions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;They must be more likely to make close pairs be candidate pairs than distant pairs.&lt;/li&gt;
&lt;li&gt;They must be statistically independent, in the sense that it is possible to estimate the probability that two or more functions will all give a certain response by the product rule for independent events.&lt;/li&gt;
&lt;li&gt;They must be efficient, in two ways:
&lt;ul&gt;
&lt;li&gt;They must be able to identify candidate pairs in time much less than the time it takes to look at all pairs.&lt;/li&gt;
&lt;li&gt;They must be combinable to build functions that are better at avoiding false positives and negatives, and the combined functions must also take time that is much less than the number of pairs.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;lsh-general-formulation&#34;&gt;LSH General Formulation&lt;/h3&gt;
&lt;p&gt;A collection of functions of this form will be called a family of functions. For example, the family of minhash functions, each based on one of the possible permutations of rows of a characteristic matrix, form a family.&lt;/p&gt;
&lt;p&gt;Let d1 &amp;lt; d2 be two distances according to some distance measure d. A family F of functions is said to be (d1, d2, p1, p2)-sensitive if for every f in F:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If d(x, y) ≤ d1, then the probability that f(x) = f(y) is at least p1.&lt;/li&gt;
&lt;li&gt;If d(x, y) ≥ d2, then the probability that f(x) = f(y) is at most p2.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;lsh-families-for-jaccard-distance&#34;&gt;LSH Families for Jaccard Distance&lt;/h3&gt;
&lt;p&gt;The family of minhash functions is a (d1, d2, 1−d1, 1−d2)-sensitive family for any d1 and d2, where 0 ≤ d1 &amp;lt; d2 ≤ 1.&lt;/p&gt;
&lt;p&gt;The reason is that if d(x, y) ≤ d1, where d is the Jaccard distance, then SIM(x, y) = 1 − d(x, y) ≥ 1 − d1. But we know that the Jaccard similarity of x and y is equal to the probability that a minhash function will hash x and y to the same value. A similar argument applies to d2 or any distance.&lt;/p&gt;
&lt;h3 id=&#34;lsh-families-for-hamming-distance&#34;&gt;LSH Families for Hamming Distance&lt;/h3&gt;
&lt;p&gt;Suppose we have a space of d-dimensional vectors, and h(x, y) denotes the Hamming distance between vectors x and y. If we take any one position of the vectors, say the ith position, we can define the function fi(x) to be the ith bit of vector x. Then f&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;(x) = f&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;(y) if and only if vectors x and
y agree in the ith position. Then the probability that f&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;(x) = f&lt;sub&gt;&lt;em&gt;i&lt;/em&gt;&lt;/sub&gt;(y) for a randomly chosen i is exactly 1 − h(x, y)/d; i.e., it is the fraction of positions in which x and y agree.&lt;/p&gt;
&lt;p&gt;This situation is almost exactly like the one we encountered for minhashing. Thus, the family F consisting of the functions {f1, f2, . . . , fd} is a (d1, d2, 1 − d1/d, 1 − d2/d)-sensitive family of hash functions, for any d1 &amp;lt; d2.&lt;/p&gt;
&lt;h3 id=&#34;lsh-families-for-cosine-distance&#34;&gt;LSH Families for Cosine Distance&lt;/h3&gt;
&lt;p&gt;Recall that the cosine distance between two vectors is the angle between the vectors. Note that these vectors may be in a space of many dimensions, but they always define a plane, and the angle between them is measured in this plane.&lt;/p&gt;
&lt;p&gt;Given two vectors x and y, say f(x) = f(y) if and only if the dot products v&lt;sub&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt; .x and v&lt;sub&gt;&lt;em&gt;f&lt;/em&gt;&lt;/sub&gt; .y have the same sign. Then F is a locality-sensitive family for the cosine distance. (d1, d2, (180 − d1)/180, (180 − d2)/180)-sensitive family of hash functions. From this basis, we can amplify the family as we wish, just as for the minhash-based family.&lt;/p&gt;
&lt;h4 id=&#34;sketches&#34;&gt;Sketches&lt;/h4&gt;
&lt;p&gt;Instead of choosing a random vector from all possible vectors, it turns out to be sufficiently random if we restrict our choice to vectors whose components are +1 and −1. The dot product of any vector x with a vector v of +1’s and −1’s is formed by adding the components of x where v is +1 and then subtracting the other components of x – those where v is −1. If we pick a collection of random vectors, say v1, v2, . . . , v&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;, then we can apply them to an arbitrary vector x by computing v1.x, v2.x, . . . , v&lt;sub&gt;&lt;em&gt;n&lt;/em&gt;&lt;/sub&gt;.x and then replacing any positive value by +1 and any negative value by −1. The result is called the sketch of x.&lt;/p&gt;
&lt;h2 id=&#34;------------mining-data-streams------------&#34;&gt;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash; MINING DATA STREAMS &amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;&lt;/h2&gt;
&lt;h2 id=&#34;filtering-data-streams&#34;&gt;Filtering Data Streams&lt;/h2&gt;
&lt;h3 id=&#34;bloom-filters&#34;&gt;Bloom Filters&lt;/h3&gt;
&lt;p&gt;A Bloom filter consists of:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;An array of n bits, initially all 0’s.&lt;/li&gt;
&lt;li&gt;A collection of hash functions h1, h2, . . . , hk. Each hash function maps “key” values to n buckets, corresponding to the n bits of the bit-array.&lt;/li&gt;
&lt;li&gt;A set S of m key values.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The purpose of the Bloom filter is to allow through all stream elements whose keys are in S, while rejecting most of the stream elements whose keys are not in S.&lt;/p&gt;
&lt;p&gt;To initialize the bit array, begin with all bits 0. Take each key value in S and hash it using each of the k hash functions. Set to 1 each bit that is hi(K) for some hash function hi and some key value K in S. To test a key K that arrives in the stream, check that all of h1(K), h2(K), . . . , hk(K) are 1’s in the bit-array. If all are 1’s, then let the stream element through. If one or more of these bits are 0, then K could not be in S, so reject the stream element.&lt;/p&gt;
&lt;h3 id=&#34;analysis-of-bloom-filters&#34;&gt;Analysis of Bloom Filters&lt;/h3&gt;
&lt;p&gt;If a key value is in S, then the element will surely pass through the Bloom filter. However, if the key value is not in S, it might still pass. We need to understand how to calculate the probability of a false positive, as a function of n, the bit-array length, m the number of members of S, and k, the number of hash functions.&lt;/p&gt;
&lt;p&gt;The model to use is throwing darts at targets. Suppose we have x targets and y darts. Any dart is equally likely to hit any target. After throwing the darts, how many targets can we expect to be hit at least once?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The probability that a given dart will not hit a given target is (x − 1)/x.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The probability that none of the y darts will hit a target is ((x − 1)/x)&lt;sup&gt;&lt;em&gt;y&lt;/em&gt;&lt;/sup&gt;. We can write this expression as,
(1- 1/x)&lt;sup&gt;&lt;em&gt;x(y/x)&lt;/em&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;using the approximation (1-q)&lt;sup&gt;&lt;em&gt;1/q&lt;/em&gt;&lt;/sup&gt; = 1/e, for small q, we conclude that the probability that none of y darts hit a given target is e&lt;sup&gt;&lt;em&gt;-y/x&lt;/em&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The optimal number of hash functions is (n/m) * ln(2).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;counting-distinct-elements-in-a-stream&#34;&gt;Counting Distinct elements in a Stream&lt;/h2&gt;
&lt;p&gt;Data stream consists of a universe of elements chosen from a set of size N. The problem is maintaining a count of the number of distinct elements seen so far. Unfortunately, we do not have the space to keep the set of elements seen so far. So we need an unbiased estimator for this count. Here we introduce the Flajolet- Martin Algorithm.&lt;/p&gt;
&lt;h3 id=&#34;flajolet---martin-algorithm&#34;&gt;Flajolet - Martin Algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Pick a has function h, that maps each of N elements to at least log&lt;sub&gt;&lt;em&gt;2&lt;/em&gt;&lt;/sub&gt;N bits.&lt;/li&gt;
&lt;li&gt;For each stream element a, let r(a) be the number of trailing zeros in h(a). And R = max&lt;sub&gt;&lt;em&gt;a&lt;/em&gt;&lt;/sub&gt;r(a), over all items a seen so far.&lt;/li&gt;
&lt;li&gt;Estimated number of distinct element is = 2&lt;sup&gt;&lt;em&gt;R&lt;/em&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;analysis-of-flajolet---martin-algorithm&#34;&gt;Analysis of Flajolet - Martin Algorithm&lt;/h3&gt;
&lt;p&gt;This estimate makes intuitive sense. The probability that a given stream element a has h(a) ending in at least r 0’s is 2&lt;sup&gt;&lt;em&gt;-r&lt;/em&gt;&lt;/sup&gt;. Suppose there are m distinct elements in the stream. Then the probability that none of them has tail length at least r is (1-2&lt;sup&gt;&lt;em&gt;-r&lt;/em&gt;&lt;/sup&gt;)&lt;sup&gt;&lt;em&gt;m&lt;/em&gt;&lt;/sup&gt;. This probability is approximately, e&lt;sup&gt;&lt;em&gt;-m2&lt;sup&gt;-r&lt;/sup&gt;&lt;/em&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;if m &amp;laquo; 2&lt;sup&gt;r&lt;/sup&gt;, then the probability that we shall find a tail of length at least r approaches 0.&lt;/li&gt;
&lt;li&gt;if m &amp;raquo; 2&lt;sup&gt;r&lt;/sup&gt;, then the probability that we shall find a tail of length at least r approaches 1.&lt;/li&gt;
&lt;li&gt;thus 2&lt;sup&gt;R&lt;/sup&gt; will be always around m.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The problem is that the probability halves when we increase R to R+1, but value doubles. We can use many hash functions h&lt;sub&gt;i&lt;/sub&gt;. and get many samples of R&lt;sub&gt;i&lt;/sub&gt; by first sorting all 2&lt;sup&gt;R&lt;/sup&gt; values. After that;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Partition your samples into small groups.&lt;/li&gt;
&lt;li&gt;Take the median of groups.&lt;/li&gt;
&lt;li&gt;Then take the average of the medians.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;computing-moments&#34;&gt;Computing Moments&lt;/h2&gt;
&lt;p&gt;In this section we consider a generalization of the problem of counting distinct elements in a stream. The problem, called computing “moments,” involves the distribution of frequencies of different elements in the stream. We shall define moments of all orders and concentrate on computing second moments, from which the general algorithm for all moments is a simple extension.&lt;/p&gt;
&lt;h3 id=&#34;definition-of-moments&#34;&gt;Definition of moments&lt;/h3&gt;
&lt;p&gt;Suppose a stream consists of elements chosen from a universal set and assume the universal set is ordered. Let m&lt;sub&gt;i&lt;/sub&gt; be the number of occurrences of the ith element for any i. Then kth moment of the stream is the sum over all i of (m&lt;sub&gt;i&lt;/sub&gt;)&lt;sup&gt;k&lt;/sup&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;0th moment&lt;/strong&gt;&lt;/strong&gt; : number of distinct elements.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;1st moment&lt;/strong&gt;&lt;/strong&gt; : length of the stream.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;2nd moment&lt;/strong&gt;&lt;/strong&gt; : a measure of how uneven the distribution is.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ams-method&#34;&gt;AMS Method&lt;/h3&gt;
&lt;p&gt;Suppose we do not have enough space to count all the mi’s for all the elements of the stream. We can still estimate the second moment of the stream using a limited amount of space; the more space we use, the more accurate the estimate will be. We compute some number of &lt;em&gt;variables&lt;/em&gt;. For each variable X, we store:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A particular element of the universal set, which we refer to as &lt;strong&gt;&lt;strong&gt;X.element&lt;/strong&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;An integer &lt;strong&gt;&lt;strong&gt;X.value&lt;/strong&gt;&lt;/strong&gt;, which is the value of the variable. To determine the value of a variable X, we choose a position in the stream between 1 and n, uniformly and at random. Set &lt;strong&gt;&lt;strong&gt;X.element&lt;/strong&gt;&lt;/strong&gt; to be the element found there, and initialize  &lt;strong&gt;&lt;strong&gt;X.value&lt;/strong&gt;&lt;/strong&gt; to 1. As we read the stream, add 1 to  &lt;strong&gt;&lt;strong&gt;X.value&lt;/strong&gt;&lt;/strong&gt; each time we encounter another occurrence of &lt;strong&gt;&lt;strong&gt;X.element&lt;/strong&gt;&lt;/strong&gt; .&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;example&#34;&gt;example:&lt;/h4&gt;
&lt;p&gt;Suppose the stream is a, b, c, b, d, a, c, d, a, b, d, c, a, a, b. The length of the stream is n = 15. Since a appears 5 times, b appears 4 times, and c and d appear three times each, the second moment for the stream is 5&lt;sup&gt;2&lt;/sup&gt;+4&lt;sup&gt;2&lt;/sup&gt;+3&lt;sup&gt;2&lt;/sup&gt;+3&lt;sup&gt;2&lt;/sup&gt; = 59. Suppose we keep three variables, X1, X2, and X3. Also, assume that at “random” we pick the 3rd, 8th, and 13th positions to define these three variables.&lt;/p&gt;
&lt;p&gt;When we reach position 3, we find element c, so we set &lt;strong&gt;&lt;strong&gt;X1.element&lt;/strong&gt;&lt;/strong&gt; = c and &lt;strong&gt;&lt;strong&gt;X1.value&lt;/strong&gt;&lt;/strong&gt;. Position 4 holds b, so we do not change X1. Likewise, nothing happens at positions 5 or 6. At position 7, we see c again, so we set &lt;strong&gt;&lt;strong&gt;X1.value&lt;/strong&gt;&lt;/strong&gt; = 2.&lt;/p&gt;
&lt;p&gt;At position 8 we find d, and so set &lt;strong&gt;&lt;strong&gt;X2.element&lt;/strong&gt;&lt;/strong&gt; = d and &lt;strong&gt;&lt;strong&gt;X2.value&lt;/strong&gt;&lt;/strong&gt; = 1. Positions 9 and 10 hold a and b, so they do not affect X1 or X2. Position 11 holds d so we set &lt;strong&gt;&lt;strong&gt;X2.value&lt;/strong&gt;&lt;/strong&gt; = 2, and position 12 holds c so we set &lt;strong&gt;&lt;strong&gt;X1.value&lt;/strong&gt;&lt;/strong&gt; = 3.&lt;/p&gt;
&lt;p&gt;At position 13, we find element a, and so set &lt;strong&gt;&lt;strong&gt;X3.element&lt;/strong&gt;&lt;/strong&gt; = a and &lt;strong&gt;&lt;strong&gt;X3.value&lt;/strong&gt;&lt;/strong&gt; = 1. Then, at position 14 we see another a and so set &lt;strong&gt;&lt;strong&gt;X3.value&lt;/strong&gt;&lt;/strong&gt; = 2. Position 15, with element b does not affect any of the variables, so we are done, with final values &lt;strong&gt;&lt;strong&gt;X1.value&lt;/strong&gt;&lt;/strong&gt; = 3 and &lt;strong&gt;&lt;strong&gt;X2.value&lt;/strong&gt;&lt;/strong&gt; = &lt;strong&gt;&lt;strong&gt;X3.value&lt;/strong&gt;&lt;/strong&gt; = 2.&lt;/p&gt;
&lt;p&gt;We can derive an estimate of the second moment from any variable X. This estimate is &lt;strong&gt;&lt;strong&gt;n(2X.value − 1)&lt;/strong&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;------dimensionality-reduction------&#34;&gt;&amp;mdash;&amp;ndash; DIMENSIONALITY REDUCTION &amp;mdash;&amp;ndash;&lt;/h2&gt;
&lt;h2 id=&#34;eigenvalues-and-eigenvectors-of-symmetric-matrixes&#34;&gt;Eigenvalues and Eigenvectors of Symmetric Matrixes&lt;/h2&gt;
&lt;p&gt;Let &lt;strong&gt;&lt;strong&gt;M&lt;/strong&gt;&lt;/strong&gt; be a square matrix. Let &lt;strong&gt;&lt;strong&gt;λ&lt;/strong&gt;&lt;/strong&gt; be a constant and e a nonzero column vector with the same number of rows as &lt;strong&gt;&lt;strong&gt;M&lt;/strong&gt;&lt;/strong&gt;. Then &lt;strong&gt;&lt;strong&gt;λ&lt;/strong&gt;&lt;/strong&gt; is an eigenvalue of &lt;strong&gt;&lt;strong&gt;M&lt;/strong&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;strong&gt;e&lt;/strong&gt;&lt;/strong&gt; is the corresponding eigenvector of &lt;strong&gt;&lt;strong&gt;M&lt;/strong&gt;&lt;/strong&gt; if &lt;strong&gt;&lt;strong&gt;Me = λe&lt;/strong&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;some-properties-of-symmetric-matrices&#34;&gt;Some properties of Symmetric Matrices&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;All eigenvalues of a symmetric matrix are real.&lt;/li&gt;
&lt;li&gt;If x is a right eigenvector of M wit eigen value λ, x is also a left eigenvector for the same eigenvalue.&lt;/li&gt;
&lt;li&gt;If M is symmetric, eigenvectors associated to different eigenvalues are mutually orthogonal.&lt;/li&gt;
&lt;li&gt;Assume V is an orthonormal eigenvector basis for a symmetric matrix M. Then, V&lt;sup&gt;T&lt;/sup&gt;V=VV&lt;sup&gt;T&lt;/sup&gt;=I. This also implies V is invertible and its inver is V&lt;sup&gt;T&lt;/sup&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;using-eigenvectors-for-dimensionality-reduction&#34;&gt;Using Eigenvectors for Dimensionality Reduction&lt;/h3&gt;
&lt;p&gt;From the example we have just worked out, we can see a general principle. If M is a matrix whose rows each represent a point in a Euclidean space with any number of dimensions, we can compute M&lt;sup&gt;T&lt;/sup&gt;M and compute its eigenpairs. Let E be the matrix whose columns are the eigenvectors, ordered as largest eigenvalue first. Define the matrix L to have the eigenvalues of M&lt;sup&gt;T&lt;/sup&gt;M along the diagonal, largest first, and 0’s in all other entries. Then, since M&lt;sup&gt;T&lt;/sup&gt;Me = λe = eλ for each eigenvector e and its corresponding eigenvalue λ, it follows that M&lt;sup&gt;T&lt;/sup&gt;M = EL.&lt;/p&gt;
&lt;p&gt;We observed that ME is the points of M transformed into a new coordinate space. In this space, the first axis (the one corresponding to the largest eigenvalue) is the most significant; formally, the variance of points along that axis is the greatest. The second axis, corresponding to the second eigenpair, is next most significant in the same sense, and the pattern continues for each of the eigenpairs. If we want to transform M to a space with fewer dimensions, then the choice that preserves the most significance is the one that uses the eigenvectors associated with the largest eigenvalues and ignores the other eigenvalues.&lt;/p&gt;
&lt;h2 id=&#34;singular-value-decomposition-svd&#34;&gt;Singular Value Decomposition (SVD)&lt;/h2&gt;
&lt;p&gt;We now take up a second form of matrix analysis that leads to a low-dimensional representation of a high-dimensional matrix. This approach, called singular- value decomposition (SVD), allows an exact representation of any matrix, and also makes it easy to eliminate the less important parts of that representation to produce an approximate representation with any desired number of dimensions.&lt;/p&gt;
&lt;h3 id=&#34;definition-of-svd&#34;&gt;Definition of SVD&lt;/h3&gt;
&lt;p&gt;Let M be an m × n matrix, and let the rank of M be r. Recall that the rank of a matrix is the largest number of rows (or equivalently columns) we can choose for which no nonzero linear combination of the rows is the all-zero vector 0 (we say a set of such rows or columns is independent). Then we can find matrices U, Sigma, and V with the following properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;U is an m × r column-orthonormal matrix ; that is, each of its columns is a unit vector and the dot product of any two columns is 0.&lt;/li&gt;
&lt;li&gt;V is an n × r column-orthonormal matrix.&lt;/li&gt;
&lt;li&gt;Sigma is a diagonal matrix; that is, all elements not on the main diagonal are 0. The elements of Sigma are called the singular values of M.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/SVD.PNG&#34; alt=&#34;SVD&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;dimensionality-reduction-using-svd&#34;&gt;Dimensionality Reduction Using SVD&lt;/h3&gt;
&lt;p&gt;Suppose we want to represent a very large matrix M by its SVD components U, Sigma, and V, but these matrices are also too large to store conveniently. The best way to reduce the dimensionality of the three matrices is to set the smallest of the singular values to zero. If we set the s smallest singular values to 0, then we can also eliminate the corresponding s columns of U and V.&lt;/p&gt;
&lt;p&gt;The choice of the lowest singular values to drop when we reduce the number of dimensions can be shown to minimize the root-mean-square error between the original matrix M and its approximation. Since the number of entries is fixed, and the square root is a monotone operation, we can simplify and compare the Frobenius norms of the matrices involved.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deep Reinforcement Learning</title>
      <link>https://copuronur.github.io/post/reinforcement/</link>
      <pubDate>Sun, 13 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/post/reinforcement/</guid>
      <description>&lt;h2 id=&#34;lecture-1introduction-to-rl&#34;&gt;LECTURE 1(Introduction to RL)&lt;/h2&gt;
&lt;h2 id=&#34;characteristic-of-reinforcement-learning&#34;&gt;Characteristic of Reinforcement Learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;There is no supervisor, only a &lt;em&gt;reward&lt;/em&gt; signal.&lt;/li&gt;
&lt;li&gt;Feedback is delayed, not instantaneous.&lt;/li&gt;
&lt;li&gt;Time matters, (sequential, not i.i.d).&lt;/li&gt;
&lt;li&gt;Agent&amp;rsquo;s actions affects the subsequent data it receives.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rewards&#34;&gt;Rewards&lt;/h3&gt;
&lt;p&gt;A reward R&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; is a scaler feedback signal indicates how well the agent is doing at step &lt;em&gt;t&lt;/em&gt;. The agents job is to maximize the cumulative reward. Reinforcement learning is based on &lt;strong&gt;&lt;strong&gt;Reward Hypothesis&lt;/strong&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;sequential-decision-making&#34;&gt;Sequential Decision Making&lt;/h3&gt;
&lt;p&gt;In RL, the actions should be selected to maximize total feature reward. Actions may have long term consequences and rewards maybe delayed. It maybe better to sacrifice immediate reward to gain more long-term reward.&lt;/p&gt;
&lt;h3 id=&#34;agent-and-environment&#34;&gt;Agent and Environment&lt;/h3&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/RLagentenv.PNG&#34; alt=&#34;Agent-Environment Interaction&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;At each time step &lt;em&gt;t&lt;/em&gt; the agent:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Executes Action A&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;.&lt;/li&gt;
&lt;li&gt;Receives observation O&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;.&lt;/li&gt;
&lt;li&gt;Receives scaler reward R&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At each time step &lt;em&gt;t&lt;/em&gt; the environment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Receives action A&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;.&lt;/li&gt;
&lt;li&gt;Emits observation O&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt;.&lt;/li&gt;
&lt;li&gt;Emits scaler reward R&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;information-state-aka-markov-state&#34;&gt;Information State (a.k.a Markov state)&lt;/h3&gt;
&lt;p&gt;An &lt;strong&gt;&lt;strong&gt;information state&lt;/strong&gt;&lt;/strong&gt; contains all the useful information from history.&lt;/p&gt;
&lt;h4 id=&#34;definition&#34;&gt;Definition&lt;/h4&gt;
&lt;p&gt;A state S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; is a &lt;strong&gt;&lt;strong&gt;Markov&lt;/strong&gt;&lt;/strong&gt; if and only if:&lt;/p&gt;
&lt;p&gt;P[S&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt;|S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;] = P[S&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt;|S&lt;sub&gt;&lt;em&gt;1&lt;/em&gt;&lt;/sub&gt;,&amp;hellip;,S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;]&lt;/p&gt;
&lt;p&gt;This means the future is independent of the past given the present.&lt;/p&gt;
&lt;h3 id=&#34;fully-observable-environments&#34;&gt;Fully Observable Environments&lt;/h3&gt;
&lt;p&gt;The observation at time &lt;em&gt;t&lt;/em&gt; is equal to Agent state at time &lt;em&gt;t&lt;/em&gt; and the environment state at time &lt;em&gt;t&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;O&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; = S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;a&lt;/em&gt;&lt;/sup&gt; = S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;e&lt;/em&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;This is a Markov decision process (&lt;strong&gt;&lt;strong&gt;MDP&lt;/strong&gt;&lt;/strong&gt;).&lt;/p&gt;
&lt;h3 id=&#34;partially-observable-environments&#34;&gt;Partially Observable Environments&lt;/h3&gt;
&lt;p&gt;The agent &lt;strong&gt;&lt;strong&gt;indirectly&lt;/strong&gt;&lt;/strong&gt; observes the environment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A robot with camera vision isn’t told its absolute location.&lt;/li&gt;
&lt;li&gt;A trading agent only observes current prices.&lt;/li&gt;
&lt;li&gt;A poker playing agent only observes public cards.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, the agent state is not equal to the environment state.  Formally, this is a Partially observable Markov decision process (&lt;strong&gt;&lt;strong&gt;POMDP&lt;/strong&gt;&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Agent must construct its own state representation S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;a&lt;/em&gt;&lt;/sup&gt;, e.g.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete history, S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;sup&gt;&lt;em&gt;a&lt;/em&gt;&lt;/sup&gt; = HS&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt;&lt;/li&gt;
&lt;li&gt;Beliefs of environment state.&lt;/li&gt;
&lt;li&gt;Recurrent neural networks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;major-components-of-an-rl-agent&#34;&gt;Major Components of an RL Agent&lt;/h2&gt;
&lt;p&gt;A RL agent may include one or more of these components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Policy: agent&amp;rsquo;s behaviour function.&lt;/li&gt;
&lt;li&gt;Value function: how good is each state and/or action.&lt;/li&gt;
&lt;li&gt;Model: agent’s representation of the environment.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;policy&#34;&gt;Policy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It is a map from state to action, e.g.
&lt;ul&gt;
&lt;li&gt;Deterministic Policy&lt;/li&gt;
&lt;li&gt;Stochastic Policy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;value-function&#34;&gt;Value Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;strong&gt;Value function&lt;/strong&gt;&lt;/strong&gt; is a prediction of future reward.&lt;/li&gt;
&lt;li&gt;Used to evaluate the goodness of states.&lt;/li&gt;
&lt;li&gt;And therefore to select between actions.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;A model&lt;/strong&gt;&lt;/strong&gt; predicts what the environment will do next.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transitions model: predicts the next state.&lt;/li&gt;
&lt;li&gt;Reward model : predicts the next reward.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;categorizing-rl-agents&#34;&gt;Categorizing RL agents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Value Based.&lt;/li&gt;
&lt;li&gt;Policy Based.&lt;/li&gt;
&lt;li&gt;Actor Critic.&lt;/li&gt;
&lt;li&gt;Model Free.&lt;/li&gt;
&lt;li&gt;Model Based.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;learning-and-planning&#34;&gt;Learning and Planning&lt;/h3&gt;
&lt;p&gt;Two fundamental problems in sequential decision making:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reinforcement Learning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The environment is initially unknown.&lt;/li&gt;
&lt;li&gt;The agent interacts with the environment.&lt;/li&gt;
&lt;li&gt;The agent improves its policy.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Planning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A model of the environment is known.&lt;/li&gt;
&lt;li&gt;The agent performs computations with its model (without any external interaction)&lt;/li&gt;
&lt;li&gt;The agent improves its policy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here you can see my &lt;a href=&#34;https://github.com/CopurOnur/Connec4-AI-bot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Connect4&lt;/a&gt; bot working with a Planning manner and finds the optimal policy with a tree search.&lt;/p&gt;
&lt;h2 id=&#34;lecture-2mdp&#34;&gt;LECTURE 2(MDP)&lt;/h2&gt;
&lt;h2 id=&#34;markov-process&#34;&gt;Markov Process&lt;/h2&gt;
&lt;h3 id=&#34;state-transition-matrix&#34;&gt;State Transition Matrix&lt;/h3&gt;
&lt;p&gt;For a Markov state s and successor state s&lt;sup&gt;&lt;em&gt;&#39;&lt;/em&gt;&lt;/sup&gt;, the state transition probability is defined by,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;P&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;ss&lt;sup&gt;&lt;/em&gt;&#39;&lt;em&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/sub&gt; =  P[S&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt; = s&lt;sup&gt;&lt;em&gt;&#39;&lt;/em&gt;&lt;/sup&gt; |S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; = s]&lt;/p&gt;
&lt;p&gt;The state transition matrix &lt;strong&gt;&lt;em&gt;&lt;strong&gt;P&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt; defines transition probabilities from all state s to all successor states s&lt;sup&gt;&lt;em&gt;&#39;&lt;/em&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/transitionmatrix.PNG&#34; alt=&#34;Transition Matrix&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;markov-process-1&#34;&gt;Markov Process&lt;/h3&gt;
&lt;p&gt;A Markov process is a memoryless random process i.e. a sequence of random states S&lt;sub&gt;1&lt;/sub&gt;,S&lt;sub&gt;2&lt;/sub&gt;&amp;hellip;S&lt;sub&gt;n&lt;/sub&gt; with Markov property.&lt;/p&gt;
&lt;h3 id=&#34;example-student-markov-chain&#34;&gt;Example :Student Markov Chain&lt;/h3&gt;
&lt;p&gt;In the figure bellow, you can see the illustration of a student Markov chain :)&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/studentmc.PNG&#34; alt=&#34;Student Markov Chain&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;markov-reward-process&#34;&gt;Markov Reward Process&lt;/h2&gt;
&lt;p&gt;A Markov reward process is a Markov chain with values.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;P&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;ss&lt;sup&gt;&lt;/em&gt;&#39;&lt;em&gt;&lt;/sup&gt;&lt;/em&gt;&lt;/sub&gt; =  P[S&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt; = s&lt;sup&gt;&lt;em&gt;&#39;&lt;/em&gt;&lt;/sup&gt; |S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; = s]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt; is a reward function, &lt;strong&gt;&lt;em&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;sub&gt;&lt;em&gt;s&lt;/em&gt;&lt;/sub&gt; =  E[R&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt; |S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; = s]&lt;/p&gt;
&lt;h3 id=&#34;return&#34;&gt;Return&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;return&lt;/em&gt; G&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; is the total discounted reward from time-step &lt;em&gt;t&lt;/em&gt; where gamma is the discount factor takes values between 0 and 1. This values immediate reward above delayed reward. Gamma close to 0 leads to ”myopic” evaluation. On the other hand Gamma close to 1 leads to ”far-sighted” evaluation.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/return.PNG&#34; alt=&#34;return&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;value-functions&#34;&gt;Value Functions&lt;/h3&gt;
&lt;p&gt;The value function &lt;strong&gt;&lt;em&gt;&lt;strong&gt;v(s)&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt; gives the long term value of state &lt;em&gt;s&lt;/em&gt;. The sate value function &lt;strong&gt;&lt;em&gt;&lt;strong&gt;v(s)&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt; of an MRP is the expected return starting from state &lt;em&gt;s&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;v(s)&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt; = E[G&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; |S&lt;sub&gt;&lt;em&gt;t&lt;/em&gt;&lt;/sub&gt; = s]&lt;/p&gt;
&lt;h3 id=&#34;bellman-equation-for-mrps&#34;&gt;Bellman Equation for MRPs&lt;/h3&gt;
&lt;p&gt;The value function can be decomposed into two parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;immediate reward R&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt;&lt;/li&gt;
&lt;li&gt;discounted value of successor state gamma * v(S&lt;sub&gt;&lt;em&gt;t+1&lt;/em&gt;&lt;/sub&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/bellman.PNG&#34; alt=&#34;Bellman equation&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;bellman-equation-in-matrix-form&#34;&gt;Bellman Equation in Matrix Form&lt;/h3&gt;
&lt;p&gt;The Bellman equation can be expressed concisely using matrices,&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/bellmanmatrix1.PNG&#34; alt=&#34;Bellman matrix 1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;where v is a column vector with one entry per state&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/bellmanmatrix2.PNG&#34; alt=&#34;Bellman matrix 2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;solving-the-bellman-equation&#34;&gt;Solving the Bellman Equation&lt;/h3&gt;
&lt;p&gt;Belllman equation is a linear equation so it can be solved directly. However the computational complexity for is O(n&lt;sup&gt;3&lt;/sup&gt;) for n states so direct solution is only possible for small MRPs. For large MRPs, the iterative methods are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dynamic programming&lt;/li&gt;
&lt;li&gt;Monte - Carlo evaluation&lt;/li&gt;
&lt;li&gt;Temporal Difference learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;markov-decision-process&#34;&gt;Markov Decision Process&lt;/h2&gt;
&lt;p&gt;A Markov decision process is a  Markov reward process with decisions. It is an environment in which all states are Markov. In the figure bellow, you can see the Student MDP. This time there is no transition probabilities but decisions and rewards. Except going to pub&amp;hellip; Once you go to a pub, you can&amp;rsquo;t make further decisions :)&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/studentmdp.PNG&#34; alt=&#34;studentmdp&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;To make decisions, we need policies.&lt;/p&gt;
&lt;h3 id=&#34;policies&#34;&gt;Policies&lt;/h3&gt;
&lt;p&gt;A policy π is a distribution over actions given states.&lt;/p&gt;
&lt;p&gt;π(a|s) = P [A&lt;sub&gt;t&lt;/sub&gt; = a | S&lt;sub&gt;t&lt;/sub&gt;  = s]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A policy fully defines the behaviour of an agent.&lt;/li&gt;
&lt;li&gt;MDP policies depend on the current state.&lt;/li&gt;
&lt;li&gt;Policies are stationary, (time independent).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given an MDP M = &amp;lt;S, A,P, R, γ&amp;gt; and a policy π,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The state sequence S&lt;sub&gt;1&lt;/sub&gt;, S&lt;sub&gt;2&lt;/sub&gt;, &amp;hellip; is a Markov process &amp;lt;S,P&lt;sup&gt;π&lt;/sup&gt;&amp;gt;.&lt;/li&gt;
&lt;li&gt;The state and reward sequence S&lt;sub&gt;1&lt;/sub&gt;, R&lt;sub&gt;1&lt;/sub&gt;, S&lt;sub&gt;2&lt;/sub&gt;, &amp;hellip; ,s a Markov reward process &amp;lt;S,P&lt;sup&gt;π&lt;/sup&gt;,R&lt;sup&gt;π&lt;/sup&gt;,γ&amp;gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/mdppolicy.PNG&#34; alt=&#34;mdppolicy&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;value-function-1&#34;&gt;Value Function&lt;/h3&gt;
&lt;h4 id=&#34;state---value-function&#34;&gt;State - Value Function&lt;/h4&gt;
&lt;p&gt;The state-value function v&lt;sup&gt;π&lt;/sup&gt;(s) of an MDP is the expected return starting from state s, and then following policy π.&lt;/p&gt;
&lt;p&gt;v&lt;sub&gt;π&lt;/sub&gt;(s) = E&lt;sub&gt;π&lt;/sub&gt; [G&lt;sub&gt;t&lt;/sub&gt; | S&lt;sub&gt;t&lt;/sub&gt; = s]&lt;/p&gt;
&lt;p&gt;The state-value function can again be decomposed into immediate reward plus discounted value of successor state.&lt;/p&gt;
&lt;p&gt;v&lt;sub&gt;π&lt;/sub&gt;(s) = E&lt;sub&gt;π&lt;/sub&gt; [R&lt;sub&gt;t+1&lt;/sub&gt; + γv&lt;sub&gt;π&lt;/sub&gt;(S&lt;sub&gt;t+1&lt;/sub&gt;) | S&lt;sub&gt;t&lt;/sub&gt; = s]&lt;/p&gt;
&lt;h4 id=&#34;action---value-function&#34;&gt;Action - Value Function&lt;/h4&gt;
&lt;p&gt;The action-value function q&lt;sup&gt;π&lt;/sup&gt;(s, a) is the expected return starting from state s, taking action a, and then following policy π.&lt;/p&gt;
&lt;p&gt;q&lt;sub&gt;π&lt;/sub&gt;(s, a) = E&lt;sub&gt;π&lt;/sub&gt; [G&lt;sub&gt;t&lt;/sub&gt; | S&lt;sub&gt;t&lt;/sub&gt; = s, A&lt;sub&gt;t&lt;/sub&gt; = a]&lt;/p&gt;
&lt;p&gt;The action-value function can similarly be decomposed,&lt;/p&gt;
&lt;p&gt;q&lt;sub&gt;π&lt;/sub&gt;(s) = E&lt;sub&gt;π&lt;/sub&gt; [R&lt;sub&gt;t+1&lt;/sub&gt; + γq&lt;sub&gt;π&lt;/sub&gt;(S&lt;sub&gt;t+1&lt;/sub&gt;,A&lt;sub&gt;t+1&lt;/sub&gt;) | S&lt;sub&gt;t&lt;/sub&gt; = s, A&lt;sub&gt;t&lt;/sub&gt; = a]&lt;/p&gt;
&lt;h3 id=&#34;optimal-value-function&#34;&gt;Optimal Value Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The optimal state-value function v&lt;sub&gt;∗&lt;/sub&gt;(s) is the maximum value function over all policies.&lt;/li&gt;
&lt;li&gt;The optimal action-value function q&lt;sub&gt;∗&lt;/sub&gt;(s, a) is the maximum action-value function over all policies&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;finding-an-optimal-policy&#34;&gt;Finding an Optimal Policy&lt;/h3&gt;
&lt;p&gt;An optimal policy can be found by maximizing over  q&lt;sub&gt;∗&lt;/sub&gt;(s, a),&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/optimalpolicy.PNG&#34; alt=&#34;optimalpolicy&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is always a deterministic optimal policy for any MDP.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the figure bellow, the red arcs shows the optimal policy for the student MDP.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://copuronur.github.io/optimalpolicystudent.PNG&#34; alt=&#34;optimalpolicystudent&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;solving-the-bellamn-optimality-equation&#34;&gt;Solving the Bellamn Optimality Equation&lt;/h3&gt;
&lt;p&gt;Bellman optimality equation is non-linear so we introduce some iterative methods such as,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Value Iteration&lt;/li&gt;
&lt;li&gt;Policy Iteration&lt;/li&gt;
&lt;li&gt;Q-learning&lt;/li&gt;
&lt;li&gt;Sarsa&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lecture-3planning-by-dp&#34;&gt;LECTURE 3(Planning by DP)&lt;/h2&gt;
&lt;h3 id=&#34;policy-evaluation&#34;&gt;Policy Evaluation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Problem : evaluate a given policy π.&lt;/li&gt;
&lt;li&gt;Solution : iterative application of Bellman expectation backup.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;v&lt;sub&gt;1&lt;/sub&gt; → v&lt;sub&gt;2&lt;/sub&gt; → &amp;hellip; → v&lt;sub&gt;π&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;Using synchronous backups,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At each iteration k + 1.&lt;/li&gt;
&lt;li&gt;For all states s ∈ S.&lt;/li&gt;
&lt;li&gt;Update v&lt;sub&gt;k+1&lt;/sub&gt;(s) from v&lt;sub&gt;k&lt;/sub&gt; (s&lt;sup&gt;&#39;&lt;/sup&gt;).&lt;/li&gt;
&lt;li&gt;where s&lt;sup&gt;&#39;&lt;/sup&gt; is the successor state of s.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;policy-iteration&#34;&gt;Policy Iteration&lt;/h3&gt;
&lt;p&gt;Given a policy π,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Evaluate&lt;/strong&gt;&lt;/strong&gt; the policy π,&lt;/p&gt;
&lt;p&gt;v&lt;sub&gt;π&lt;/sub&gt;(s) = E[R&lt;sub&gt;t+1&lt;/sub&gt; + R&lt;sub&gt;t+2&lt;/sub&gt; + &amp;hellip;  | S&lt;sub&gt;t&lt;/sub&gt; = s]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;strong&gt;Improve&lt;/strong&gt;&lt;/strong&gt; the policy by acting greedily with respect to v&lt;sub&gt;π&lt;/sub&gt;.&lt;/p&gt;
&lt;p&gt;this process of &lt;strong&gt;&lt;strong&gt;policy iteration&lt;/strong&gt;&lt;/strong&gt; always converges to π∗&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Periodic Route Optimization for FMCG Distributors</title>
      <link>https://copuronur.github.io/publication/conference-paper1/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/publication/conference-paper1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://copuronur.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Emotion Recognition CNN</title>
      <link>https://copuronur.github.io/project/emotion_recognition/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/project/emotion_recognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Engagement Detection with OpenFace &amp; Bi-LSTM</title>
      <link>https://copuronur.github.io/project/engagement_detection/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/project/engagement_detection/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NBA Statistics</title>
      <link>https://copuronur.github.io/project/nba-statistics/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/project/nba-statistics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SVM from Scratch</title>
      <link>https://copuronur.github.io/project/svm/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/project/svm/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://copuronur.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://copuronur.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
