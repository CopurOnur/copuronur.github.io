[{"authors":null,"categories":null,"content":"Data scientist with research interests in computer vision and NLP. Proficient in Python programming, MLOps and deep learning frameworks.\n  Download my resumé.\n","date":1625097600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1625097600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://copuronur.github.io/author/onur-copur/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/onur-copur/","section":"authors","summary":"Data scientist with research interests in computer vision and NLP. Proficient in Python programming, MLOps and deep learning frameworks.\n  Download my resumé.","tags":null,"title":"Onur Copur","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://copuronur.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Mert Nakip","Onur Copur","Cüneyt Güzeliş"],"categories":null,"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://copuronur.github.io/publication/conference-paper/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"This paper gives an explanation for the failure of machine learning models for the prediction of the cases and the other future trends of Covid-19 pandemic. The paper shows that simple Linear Regression models provide high prediction accuracy values reliably but only for a 2-weeks period and that relatively complex machine learning models, which have the potential of learning long-term predictions with low errors, cannot achieve to obtain good predictions with possessing a high generalization ability. It is suggested in the paper that the lack of a sufficient number of samples is the source of the low prediction performance of the forecasting models. To exploit the information, which is of most relevant with the active cases, we perform feature selection over a variety of variables such as the numbers of active cases, deaths, recoveries, and population. Furthermore, we compare Linear Regression, Multi-Layer Perceptron, and Long-Short Term Memory models each of which is used for prediction of active cases together with various feature selection methods. Our results show that the accurate forecasting of the active cases with high generalization ability is possible up to 3 days because of the small sample size of COVID-19 data. We observe that the Linear Regression model has much better prediction performance with high generalization ability as compared to the complex models but, as expected, its performance decays sharply for more than 14-days prediction horizons.","tags":null,"title":"Comparative Study of Forecasting Models for COVID-19 Outbreak in Turkey","type":"publication"},{"authors":["Onur Copur"],"categories":null,"content":"\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; MAP REDUCE \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; Distributed File System (DFS) Modern data-mining applications, often called “big-data” analysis, require us to manage immense amounts of data quickly. The key factor of making fast computation is parallelization and this is done via computer clusters. To exploit cluster computing, files must look and behave somewhat differently from the conventional file systems found on single computers. This new file system is called Distributed File System (DFS).\n DFS is suitable for enormous, possibly a terabyte in size. If you have only small files, there is no point using a DFS for them. Files are rarely updated. Rather, they are read as data for some calculation, and possibly additional data is appended to files from time to time.  One problem in parallel computing is the machine failures. If you have a large computing clusters, you are likely to observe frequent machine failures. To overcome this challenge, Files are dived into chunks and each chunk is replicated in different nodes (chunk servers) of the cluster. Moreover, the nodes holding copies of one chunk should be located on different racks, so we don’t lose all copies due to a rack failure. In the figure bellow, you can see the diagram of a distributed file system. Note that the chunk servers also serve as compute servers.\n   The two other components of DFS (which are not shown in figure) are Master Node and Client library. Master node stores meta data about where files are stored and Client library talks to master to find chunk servers. The other problem in big data computing is moving data around for different computations is computationally expensive. The way to handle this problem is bring\tcomputation close\tto the\tdata. MapReduce is the programming model introduced to handle these problems and DFS is the Storage Infrastructure - File system associated with this programming model.\nMapReduce Implementation (centralized) Implementation of MapReduce requires the programmer to write two functions, called Map and Reduce. In brief, a MapReduce computation executes as follows:\n  Some number of Map tasks each are given one or more chunks from a DFS. These Map tasks turn the chunk into a sequence of key-value pairs.\n  The key-value pairs from each Map task are collected by a master controller and sorted by key. The keys are divided among all the Reduce tasks, so all key-value pairs with the same key wind up at the same Reduce task.\n  The Reduce tasks work on one key at a time, and combine all the values associated with that key in some way.\n  In the diagram bellow, you can see a MapReduce implementation for the word count task. Note that this scheme shows how MapReduce works in a centralized system.\n   MapReduce Implementation (Parallel) However we are more interested in MapReduce in a computer cluster. In a computer cluster Map and Reduce tasks are running in parallel on multiple nodes. As we mentioned before, same data chunks can appear in different nodes and different Map tasks maybe processing same data chunks. But for the reduce tasks, we want put all key-value pairs with same key to the same reduce task. Here we introduce the Partitioning Function which is just a hash function responsible from this operation. In the figure bellow, you can see the MapReduce reduce diagram in parallel.\n   MapReduce environment duties:  Partitioning the input data. Scheduling the program\u0026rsquo;s execution across a set of machines. Performing the group by key step. Handling machine failures. Managing required intermachine communication.  Data Flow  Input and final output are stored on the DFS.  Scheduler tries to schedule map tasks to each chunk server which contains corresponding data chunk.   Intermediate results are stored on local file system of Map and Reduce workers.  Details of MapReduce Execution The figure bellow offers an outline of how process, tasks and files interact. Taking advantage of a client library provided by a MapReduce system, the user program forks a Master Controller process and some number of Map workers and Reduce workers. Note that a worker handles either Map tasks or Reduce tasks.\nThe Master has many responsibilities. One is to create some number of Map tasks and some number of Reduce tasks, these numbers being selected by the user program. These tasks will be assigned to Worker processes by the Master. It is reasonable to create one Map task for every chunk of the input file(s), but we may wish to create fewer Reduce tasks. The reason for limiting the number of Reduce tasks is that it is necessary for each Map task to create an intermediate file for each Reduce task, and if there are too many Reduce tasks the number of intermediate files explodes. The Master keeps track of the status of each Map and Reduce task (idle, executing at a particular Worker, or completed). A Worker process reports to the Master when it finishes a task, and a new task is scheduled by the Master for that Worker process.\nEach Map task is assigned one or more chunks of the input file(s) and executes on it the code written by the user. The Map task creates a file for each Reduce task on the local disk of the Worker that executes the Map task. The Master is informed of the location and sizes of each of these files, and the Reduce task for which each is destined. When a Reduce task is assigned by the Master to a Worker process, that task is given all the files that form its input. The Reduce task executes code written by the user and writes its output to a file that is part of the surrounding distributed file system.\n   Dealing With Failures  Map worker failure.  Map tasks completed or in-progress at worker are rest to idle. Reduce workers are notified when task is rescheduled on another worker.   Reduce worker failure.  Only in-progress tasks are reset to idle. Idle Reduce tasks restarted on other worker(s).   Master failure.  Map reduce task is aborted and client notified.    Refinements Combiners  Often a Map task will produce many key-value pairs with same key. We can save time by pre-aggregating values with same key in the mapper.  combine(k, list(v1)) -\u0026gt; v2. Combiner\tis\tusually\tsame as\tthe\treduce\tfunction. Works\tonly\tif\treduce function\tis\tcommutative\tand\tassociative.    Partition Function  Want to control how keys get partitioned. System uses a default Partition function:  hash(key) mod R.   Sometimes useful to override the hash function.  Algorithms Using MapReduce The original purpose for which the Google implementation of MapReduce was created was to execute very large matrix-vector multiplications as are needed in the calculation of PageRank.\nMatrix-Vector Multiplication by MapReduce Suppose we have an n x n matrix M, whose element in row i and column j will be denoted mij . Suppose we also have a vector v of length n, whose jth element is vj .\nThe Map function Each Map task will operate on a chunk of the matrix M. From each matrix element mij it produces the key-value pair (i,mijvj). Thus, all terms of the sum that make up the component xi of the matrix-vector product will get the same key, i.\nThe Reduce function The Reduce function simply sums all the values associated with a given key i. The result will be a pair (i, xi).\nNote that parallelization of matrix multiplication is very crucial at neural net computations.\nNatural Join by MapReduce Natural join is a frequently used operation in relational database system and parallelization of this operation saves enormous computing time. In the figure bellow yo can see the illustration of Natural Join.\n    Use a hash function h from B-values to 1..k A map process turns:  each input tuple R(a,b) into key-value pair (b, (a,R)). each input tuple S(b,c) into key-value pair (b, (c,S)).   Map process send each key-value pair with key b to Reduce process h(b). Each reduce process matches all the pairs (b, (a,R)) with all (b, (c,S)) and outputs (a,b,c)  Cost Measures for MapReduce Algorithms Communication Cost input file size + 2x(sum of the sizes of all files passed from Map process to Reduce process) + the sum of the output sizes of the reduce process.\nElapsed Communication Cost sum of the largest input + output for any map process + output for any map process\nReferences  http://web.stanford.edu/class/cs246/ http://www.mmds.org/#ver21  \u0026mdash;- FINDING SIMMILAR DOCUMNETS \u0026mdash;- Shingling of Documents The most effective way to represent documents as sets, for the purpose of identifying lexically similar documents is to construct from the document the set of short strings that appear within it.\nk-Shingles or k-gram A document is a string of characters. Define a k-shingle for a document to be any substring of length k found within the document. Then, we may associate with each document the set of k-shingles that appear one or more times within that document. Instead of using substrings directly as shingles, we can pick a hash function that maps strings of length k to some number of buckets and treat the resulting bucket number as the shingle. The set representing a document is then the set of integers that are bucket numbers of one or more k-shingles that appear in the document. The result of hashing shingles also called tokens.\nSimilarity-Preserving Summaries of Sets Signatures Sets of shingles are large. Even if we hash them to four bytes each, the space needed to store a set is still roughly four times the space taken by the document. If we have millions of documents, it may well not be possible to store all the shingle-sets in main memory.\nOur goal in this section is to replace large sets by much smaller representations called “signatures.” The important property we need for signatures is that we can compare the signatures of two sets and estimate the Jaccard similarity of the underlying sets from the signatures alone.\nMinhashing The signatures we desire to construct for sets are composed of the results of a large number of calculations, say several hundred, each of which is a “minhash” of the characteristic matrix. In this section, we shall learn how a minhash is computed in principle, and in later sections we shall see how a good approximation to the minhash is computed in practice.\nTo minhash a set represented by a column of the characteristic matrix, pick a permutation of the rows. The minhash value of any column is the number of the first row, in the permuted order, in which the column has a 1. In the table bellow, you can see an example of minhash table with size 3. The input matrix is a matrix with binary input which has documents in the columns and shingles (tokens) in the rows and this input matrix I, has Iij =1, if document j contains token i. To calculate the minhash matrix, first we generate 3 different permutation of rows. Lets check the blue permutation. the first row in the blue permutation refers to the sixth row in the input matrix. In the sixth row we see that columns 1 and 3 has inputs 1, so we put the permutation row number (1 in this case) to the first and third columns of the signature vector. the second row in the blue permutation refers to the fourth row in the input matrix. In the fourth row we see that columns 2 and 4 has inputs 1, so we put the permutation row number (2 in this case) to the second and fourth columns of the signature vector. As we filled all columns for the blue permutation, we can proceed to other permutations and fill the column values in the same manner.\n   Minhashing and Jaccard Similarity There is a remarkable connection between minhashing and Jaccard similarity of the sets that are minhashed.\nThe probability that the minhash function for a random permutation of rows produces the same value for two sets equals the Jaccard similarity of those sets.\nComputation of Minhas Permutations It is not feasible to permute a large characteristic matrix explicitly. Even picking a random permutation of millions or billions of rows is time-consuming, and the necessary sorting of the rows would take even more time.\nFortunately, it is possible to simulate the effect of a random permutation by a random hash function that maps row numbers to as many buckets as there are rows. A hash function that maps integers 0, 1, . . . , k −1 to bucket numbers 0 through k−1 typically will map some pairs of integers to the same bucket and leave other buckets unfilled. However, the difference is unimportant as long as k is large and there are not too many collisions. We can maintain the fiction that our hash function h “permutes” row r to position h(r) in the permuted order. Thus, instead of picking n random permutations of rows, we pick n randomly chosen hash functions h1, h2, . . . , hn on the rows. We construct the signature matrix by considering each row in their given order.\nLocality Sensitive Hashing (LSH) The general Idea of LSH is generating a small list of candidate pairs (pairs of elements whose similarity must be evaluated) from the collection of all elements. This is done via “hashing” items several times, in such a way that similar items are more likely to be hashed to the same bucket than dissimilar items are. We then consider any pair that hashed to the same bucket for any of the hashings to be a candidate pair. We check only the candidate pairs for similarity.\nLSH for Minhash Signatures Even though we can use minhashing to compress large documents into small signatures and preserve the expected similarity of any pair of documents, it still may be impossible to find the pairs with greatest similarity efficiently. The reason is that the number of pairs of documents may be too large, even if there are not too many documents. So we refer to the idea of LSH we mentioned above.\nIf we have minhash signatures for the items, an effective way to choose the hashings is to divide the signature matrix into b bands consisting of r rows each. For each band, there is a hash function that takes vectors of r integers (the portion of one column within that band) and hashes them to some large number of buckets. We can use the same hash function for all the bands, but we use a separate bucket array for each band, so columns with the same vector in different bands will not hash to the same bucket. In the figure bellow, you can see hash table for a single band in a signature matrix.\n   Analysis of the Banding Technique Suppose we use b bands of r rows each, and suppose that a particular pair of documents have Jaccard similarity s. Recall that the probability the minhash signatures for these documents agree in any one particular row of the signature matrix is s. We can calculate the probability that these documents (or rather their signatures) become a candidate pair as follows:\n The probability that the signatures agree in all rows of one particular band is sr. The probability that the signatures disagree in at least one row of a particular band is 1- sr. The probability that the signatures disagree in at least one row of each of the bands is (1- sr)b (also the probability of false negatives for s \u0026gt; threshold). The probability that the signatures agree in all the rows of at least one band, and therefore become a candidate pair, is 1- (1- sr)b. (also the probability of false positives for s \u0026lt; threshold).  It may not be obvious, but regardless of the chosen constants b and r, this function has the form of an S-curve, as suggested in the figure bellow and an approximation for the threshold is (1/b)1/r. If you want a high recall value, it is better to have high r and low 0\n   The Theory of Locality-Sensitive Functions Now, we shall explore other families of functions, besides the minhash functions, that can serve to produce candidate pairs efficiently. These functions can apply to the space of sets and the Jaccard distance, or to another space and/or another distance measure. There are three conditions that we need for a family of functions:\n They must be more likely to make close pairs be candidate pairs than distant pairs. They must be statistically independent, in the sense that it is possible to estimate the probability that two or more functions will all give a certain response by the product rule for independent events. They must be efficient, in two ways:  They must be able to identify candidate pairs in time much less than the time it takes to look at all pairs. They must be combinable to build functions that are better at avoiding false positives and negatives, and the combined functions must also take time that is much less than the number of pairs.    LSH General Formulation A collection of functions of this form will be called a family of functions. For example, the family of minhash functions, each based on one of the possible permutations of rows of a characteristic matrix, form a family.\nLet d1 \u0026lt; d2 be two distances according to some distance measure d. A family F of functions is said to be (d1, d2, p1, p2)-sensitive if for every f in F:\n If d(x, y) ≤ d1, then the probability that f(x) = f(y) is at least p1. If d(x, y) ≥ d2, then the probability that f(x) = f(y) is at most p2.  LSH Families for Jaccard Distance The family of minhash functions is a (d1, d2, 1−d1, 1−d2)-sensitive family for any d1 and d2, where 0 ≤ d1 \u0026lt; d2 ≤ 1.\nThe reason is that if d(x, y) ≤ d1, where d is the Jaccard distance, then SIM(x, y) = 1 − d(x, y) ≥ 1 − d1. But we know that the Jaccard similarity of x and y is equal to the probability that a minhash function will hash x and y to the same value. A similar argument applies to d2 or any distance.\nLSH Families for Hamming Distance Suppose we have a space of d-dimensional vectors, and h(x, y) denotes the Hamming distance between vectors x and y. If we take any one position of the vectors, say the ith position, we can define the function fi(x) to be the ith bit of vector x. Then fi(x) = fi(y) if and only if vectors x and y agree in the ith position. Then the probability that fi(x) = fi(y) for a randomly chosen i is exactly 1 − h(x, y)/d; i.e., it is the fraction of positions in which x and y agree.\nThis situation is almost exactly like the one we encountered for minhashing. Thus, the family F consisting of the functions {f1, f2, . . . , fd} is a (d1, d2, 1 − d1/d, 1 − d2/d)-sensitive family of hash functions, for any d1 \u0026lt; d2.\nLSH Families for Cosine Distance Recall that the cosine distance between two vectors is the angle between the vectors. Note that these vectors may be in a space of many dimensions, but they always define a plane, and the angle between them is measured in this plane.\nGiven two vectors x and y, say f(x) = f(y) if and only if the dot products vf .x and vf .y have the same sign. Then F is a locality-sensitive family for the cosine distance. (d1, d2, (180 − d1)/180, (180 − d2)/180)-sensitive family of hash functions. From this basis, we can amplify the family as we wish, just as for the minhash-based family.\nSketches Instead of choosing a random vector from all possible vectors, it turns out to be sufficiently random if we restrict our choice to vectors whose components are +1 and −1. The dot product of any vector x with a vector v of +1’s and −1’s is formed by adding the components of x where v is +1 and then subtracting the other components of x – those where v is −1. If we pick a collection of random vectors, say v1, v2, . . . , vn, then we can apply them to an arbitrary vector x by computing v1.x, v2.x, . . . , vn.x and then replacing any positive value by +1 and any negative value by −1. The result is called the sketch of x.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; MINING DATA STREAMS \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; Filtering Data Streams Bloom Filters A Bloom filter consists of:\n An array of n bits, initially all 0’s. A collection of hash functions h1, h2, . . . , hk. Each hash function maps “key” values to n buckets, corresponding to the n bits of the bit-array. A set S of m key values.  The purpose of the Bloom filter is to allow through all stream elements whose keys are in S, while rejecting most of the stream elements whose keys are not in S.\nTo initialize the bit array, begin with all bits 0. Take each key value in S and hash it using each of the k hash functions. Set to 1 each bit that is hi(K) for some hash function hi and some key value K in S. To test a key K that arrives in the stream, check that all of h1(K), h2(K), . . . , hk(K) are 1’s in the bit-array. If all are 1’s, then let the stream element through. If one or more of these bits are 0, then K could not be in S, so reject the stream element.\nAnalysis of Bloom Filters If a key value is in S, then the element will surely pass through the Bloom filter. However, if the key value is not in S, it might still pass. We need to understand how to calculate the probability of a false positive, as a function of n, the bit-array length, m the number of members of S, and k, the number of hash functions.\nThe model to use is throwing darts at targets. Suppose we have x targets and y darts. Any dart is equally likely to hit any target. After throwing the darts, how many targets can we expect to be hit at least once?\n  The probability that a given dart will not hit a given target is (x − 1)/x.\n  The probability that none of the y darts will hit a target is ((x − 1)/x)y. We can write this expression as, (1- 1/x)x(y/x).\n  using the approximation (1-q)1/q = 1/e, for small q, we conclude that the probability that none of y darts hit a given target is e-y/x.\n  The optimal number of hash functions is (n/m) * ln(2).\n  Counting Distinct elements in a Stream Data stream consists of a universe of elements chosen from a set of size N. The problem is maintaining a count of the number of distinct elements seen so far. Unfortunately, we do not have the space to keep the set of elements seen so far. So we need an unbiased estimator for this count. Here we introduce the Flajolet- Martin Algorithm.\nFlajolet - Martin Algorithm  Pick a has function h, that maps each of N elements to at least log2N bits. For each stream element a, let r(a) be the number of trailing zeros in h(a). And R = maxar(a), over all items a seen so far. Estimated number of distinct element is = 2R.  Analysis of Flajolet - Martin Algorithm This estimate makes intuitive sense. The probability that a given stream element a has h(a) ending in at least r 0’s is 2-r. Suppose there are m distinct elements in the stream. Then the probability that none of them has tail length at least r is (1-2-r)m. This probability is approximately, e-m2-r.\n if m \u0026laquo; 2r, then the probability that we shall find a tail of length at least r approaches 0. if m \u0026raquo; 2r, then the probability that we shall find a tail of length at least r approaches 1. thus 2R will be always around m.  The problem is that the probability halves when we increase R to R+1, but value doubles. We can use many hash functions hi. and get many samples of Ri by first sorting all 2R values. After that;\n Partition your samples into small groups. Take the median of groups. Then take the average of the medians.  Computing Moments In this section we consider a generalization of the problem of counting distinct elements in a stream. The problem, called computing “moments,” involves the distribution of frequencies of different elements in the stream. We shall define moments of all orders and concentrate on computing second moments, from which the general algorithm for all moments is a simple extension.\nDefinition of moments Suppose a stream consists of elements chosen from a universal set and assume the universal set is ordered. Let mi be the number of occurrences of the ith element for any i. Then kth moment of the stream is the sum over all i of (mi)k.\n 0th moment : number of distinct elements. 1st moment : length of the stream. 2nd moment : a measure of how uneven the distribution is.  AMS Method Suppose we do not have enough space to count all the mi’s for all the elements of the stream. We can still estimate the second moment of the stream using a limited amount of space; the more space we use, the more accurate the estimate will be. We compute some number of variables. For each variable X, we store:\n A particular element of the universal set, which we refer to as X.element. An integer X.value, which is the value of the variable. To determine the value of a variable X, we choose a position in the stream between 1 and n, uniformly and at random. Set X.element to be the element found there, and initialize X.value to 1. As we read the stream, add 1 to X.value each time we encounter another occurrence of X.element .  example: Suppose the stream is a, b, c, b, d, a, c, d, a, b, d, c, a, a, b. The length of the stream is n = 15. Since a appears 5 times, b appears 4 times, and c and d appear three times each, the second moment for the stream is 52+42+32+32 = 59. Suppose we keep three variables, X1, X2, and X3. Also, assume that at “random” we pick the 3rd, 8th, and 13th positions to define these three variables.\nWhen we reach position 3, we find element c, so we set X1.element = c and X1.value. Position 4 holds b, so we do not change X1. Likewise, nothing happens at positions 5 or 6. At position 7, we see c again, so we set X1.value = 2.\nAt position 8 we find d, and so set X2.element = d and X2.value = 1. Positions 9 and 10 hold a and b, so they do not affect X1 or X2. Position 11 holds d so we set X2.value = 2, and position 12 holds c so we set X1.value = 3.\nAt position 13, we find element a, and so set X3.element = a and X3.value = 1. Then, at position 14 we see another a and so set X3.value = 2. Position 15, with element b does not affect any of the variables, so we are done, with final values X1.value = 3 and X2.value = X3.value = 2.\nWe can derive an estimate of the second moment from any variable X. This estimate is n(2X.value − 1).\n\u0026mdash;\u0026ndash; DIMENSIONALITY REDUCTION \u0026mdash;\u0026ndash; Eigenvalues and Eigenvectors of Symmetric Matrixes Let M be a square matrix. Let λ be a constant and e a nonzero column vector with the same number of rows as M. Then λ is an eigenvalue of M and e is the corresponding eigenvector of M if Me = λe.\nSome properties of Symmetric Matrices  All eigenvalues of a symmetric matrix are real. If x is a right eigenvector of M wit eigen value λ, x is also a left eigenvector for the same eigenvalue. If M is symmetric, eigenvectors associated to different eigenvalues are mutually orthogonal. Assume V is an orthonormal eigenvector basis for a symmetric matrix M. Then, VTV=VVT=I. This also implies V is invertible and its inver is VT.  Using Eigenvectors for Dimensionality Reduction From the example we have just worked out, we can see a general principle. If M is a matrix whose rows each represent a point in a Euclidean space with any number of dimensions, we can compute MTM and compute its eigenpairs. Let E be the matrix whose columns are the eigenvectors, ordered as largest eigenvalue first. Define the matrix L to have the eigenvalues of MTM along the diagonal, largest first, and 0’s in all other entries. Then, since MTMe = λe = eλ for each eigenvector e and its corresponding eigenvalue λ, it follows that MTM = EL.\nWe observed that ME is the points of M transformed into a new coordinate space. In this space, the first axis (the one corresponding to the largest eigenvalue) is the most significant; formally, the variance of points along that axis is the greatest. The second axis, corresponding to the second eigenpair, is next most significant in the same sense, and the pattern continues for each of the eigenpairs. If we want to transform M to a space with fewer dimensions, then the choice that preserves the most significance is the one that uses the eigenvectors associated with the largest eigenvalues and ignores the other eigenvalues.\nSingular Value Decomposition (SVD) We now take up a second form of matrix analysis that leads to a low-dimensional representation of a high-dimensional matrix. This approach, called singular- value decomposition (SVD), allows an exact representation of any matrix, and also makes it easy to eliminate the less important parts of that representation to produce an approximate representation with any desired number of dimensions.\nDefinition of SVD Let M be an m × n matrix, and let the rank of M be r. Recall that the rank of a matrix is the largest number of rows (or equivalently columns) we can choose for which no nonzero linear combination of the rows is the all-zero vector 0 (we say a set of such rows or columns is independent). Then we can find matrices U, Sigma, and V with the following properties:\n U is an m × r column-orthonormal matrix ; that is, each of its columns is a unit vector and the dot product of any two columns is 0. V is an n × r column-orthonormal matrix. Sigma is a diagonal matrix; that is, all elements not on the main diagonal are 0. The elements of Sigma are called the singular values of M.     Dimensionality Reduction Using SVD Suppose we want to represent a very large matrix M by its SVD components U, Sigma, and V, but these matrices are also too large to store conveniently. The best way to reduce the dimensionality of the three matrices is to set the smallest of the singular values to zero. If we set the s smallest singular values to 0, then we can also eliminate the corresponding s columns of U and V.\nThe choice of the lowest singular values to drop when we reduce the number of dimensions can be shown to minimize the root-mean-square error between the original matrix M and its approximation. Since the number of entries is fixed, and the square root is a monotone operation, we can simplify and compare the Frobenius norms of the matrices involved.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://copuronur.github.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; MAP REDUCE \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; Distributed File System (DFS) Modern data-mining applications, often called “big-data” analysis, require us to manage immense amounts of data quickly. The key factor of making fast computation is parallelization and this is done via computer clusters.","tags":null,"title":"Big Data computing","type":"post"},{"authors":["Onur Copur"],"categories":null,"content":"LECTURE 1(Introduction to RL) Characteristic of Reinforcement Learning  There is no supervisor, only a reward signal. Feedback is delayed, not instantaneous. Time matters, (sequential, not i.i.d). Agent\u0026rsquo;s actions affects the subsequent data it receives.  Rewards A reward Rt is a scaler feedback signal indicates how well the agent is doing at step t. The agents job is to maximize the cumulative reward. Reinforcement learning is based on Reward Hypothesis.\nSequential Decision Making In RL, the actions should be selected to maximize total feature reward. Actions may have long term consequences and rewards maybe delayed. It maybe better to sacrifice immediate reward to gain more long-term reward.\nAgent and Environment    At each time step t the agent:\n Executes Action At. Receives observation Ot. Receives scaler reward Rt.  At each time step t the environment:\n Receives action At. Emits observation Ot+1. Emits scaler reward Rt+1  Information State (a.k.a Markov state) An information state contains all the useful information from history.\nDefinition A state St is a Markov if and only if:\nP[St+1|St] = P[St+1|S1,\u0026hellip;,St]\nThis means the future is independent of the past given the present.\nFully Observable Environments The observation at time t is equal to Agent state at time t and the environment state at time t.\nOt = Sta = Ste.\nThis is a Markov decision process (MDP).\nPartially Observable Environments The agent indirectly observes the environment.\n A robot with camera vision isn’t told its absolute location. A trading agent only observes current prices. A poker playing agent only observes public cards.  Now, the agent state is not equal to the environment state. Formally, this is a Partially observable Markov decision process (POMDP).\nAgent must construct its own state representation Sta, e.g.\n Complete history, Sta = HSt Beliefs of environment state. Recurrent neural networks.  Major Components of an RL Agent A RL agent may include one or more of these components.\n Policy: agent\u0026rsquo;s behaviour function. Value function: how good is each state and/or action. Model: agent’s representation of the environment.  Policy  It is a map from state to action, e.g.  Deterministic Policy Stochastic Policy    Value Function  Value function is a prediction of future reward. Used to evaluate the goodness of states. And therefore to select between actions.  Model A model predicts what the environment will do next.\n Transitions model: predicts the next state. Reward model : predicts the next reward.  Categorizing RL agents  Value Based. Policy Based. Actor Critic. Model Free. Model Based.  Learning and Planning Two fundamental problems in sequential decision making:\n  Reinforcement Learning:\n The environment is initially unknown. The agent interacts with the environment. The agent improves its policy.    Planning:\n A model of the environment is known. The agent performs computations with its model (without any external interaction) The agent improves its policy    Here you can see my Connect4 bot working with a Planning manner and finds the optimal policy with a tree search.\nLECTURE 2(MDP) Markov Process State Transition Matrix For a Markov state s and successor state s', the state transition probability is defined by,\nPss' = P[St+1 = s' |St = s]\nThe state transition matrix P defines transition probabilities from all state s to all successor states s'.\n   Markov Process A Markov process is a memoryless random process i.e. a sequence of random states S1,S2\u0026hellip;Sn with Markov property.\nExample :Student Markov Chain In the figure bellow, you can see the illustration of a student Markov chain :)\n   Markov Reward Process A Markov reward process is a Markov chain with values.\nPss' = P[St+1 = s' |St = s]\nR is a reward function, Rs = E[Rt+1 |St = s]\nReturn The return Gt is the total discounted reward from time-step t where gamma is the discount factor takes values between 0 and 1. This values immediate reward above delayed reward. Gamma close to 0 leads to ”myopic” evaluation. On the other hand Gamma close to 1 leads to ”far-sighted” evaluation.\n   Value Functions The value function v(s) gives the long term value of state s. The sate value function v(s) of an MRP is the expected return starting from state s.\nv(s) = E[Gt |St = s]\nBellman Equation for MRPs The value function can be decomposed into two parts:\n immediate reward Rt+1 discounted value of successor state gamma * v(St+1)     Bellman Equation in Matrix Form The Bellman equation can be expressed concisely using matrices,\n   where v is a column vector with one entry per state\n   Solving the Bellman Equation Belllman equation is a linear equation so it can be solved directly. However the computational complexity for is O(n3) for n states so direct solution is only possible for small MRPs. For large MRPs, the iterative methods are:\n Dynamic programming Monte - Carlo evaluation Temporal Difference learning  Markov Decision Process A Markov decision process is a Markov reward process with decisions. It is an environment in which all states are Markov. In the figure bellow, you can see the Student MDP. This time there is no transition probabilities but decisions and rewards. Except going to pub\u0026hellip; Once you go to a pub, you can\u0026rsquo;t make further decisions :)\n   To make decisions, we need policies.\nPolicies A policy π is a distribution over actions given states.\nπ(a|s) = P [At = a | St = s]\n A policy fully defines the behaviour of an agent. MDP policies depend on the current state. Policies are stationary, (time independent).  Given an MDP M = \u0026lt;S, A,P, R, γ\u0026gt; and a policy π,\n The state sequence S1, S2, \u0026hellip; is a Markov process \u0026lt;S,Pπ\u0026gt;. The state and reward sequence S1, R1, S2, \u0026hellip; ,s a Markov reward process \u0026lt;S,Pπ,Rπ,γ\u0026gt;.     Value Function State - Value Function The state-value function vπ(s) of an MDP is the expected return starting from state s, and then following policy π.\nvπ(s) = Eπ [Gt | St = s]\nThe state-value function can again be decomposed into immediate reward plus discounted value of successor state.\nvπ(s) = Eπ [Rt+1 + γvπ(St+1) | St = s]\nAction - Value Function The action-value function qπ(s, a) is the expected return starting from state s, taking action a, and then following policy π.\nqπ(s, a) = Eπ [Gt | St = s, At = a]\nThe action-value function can similarly be decomposed,\nqπ(s) = Eπ [Rt+1 + γqπ(St+1,At+1) | St = s, At = a]\nOptimal Value Function  The optimal state-value function v∗(s) is the maximum value function over all policies. The optimal action-value function q∗(s, a) is the maximum action-value function over all policies  Finding an Optimal Policy An optimal policy can be found by maximizing over q∗(s, a),\n    There is always a deterministic optimal policy for any MDP.  In the figure bellow, the red arcs shows the optimal policy for the student MDP.\n   Solving the Bellamn Optimality Equation Bellman optimality equation is non-linear so we introduce some iterative methods such as,\n Value Iteration Policy Iteration Q-learning Sarsa  LECTURE 3(Planning by DP) Policy Evaluation  Problem : evaluate a given policy π. Solution : iterative application of Bellman expectation backup.  v1 → v2 → \u0026hellip; → vπ\nUsing synchronous backups,\n At each iteration k + 1. For all states s ∈ S. Update vk+1(s) from vk (s'). where s' is the successor state of s.  Policy Iteration Given a policy π,\nEvaluate the policy π,\nvπ(s) = E[Rt+1 + Rt+2 + \u0026hellip; | St = s]\nImprove the policy by acting greedily with respect to vπ.\nthis process of policy iteration always converges to π∗\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"9ad8b4592642b80ffd33d8d9cad0fbd4","permalink":"https://copuronur.github.io/post/reinforcement/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/reinforcement/","section":"post","summary":"This is a blog post about the UCL course on Reinforcement Learning by [David Silver](). The course is divided into 10 Lectures and I will share my notes on every lecture in this post.","tags":null,"title":"Deep Reinforcement Learning","type":"post"},{"authors":["Onur Copur","Mert Yıldız","Simru Göven","Ali Övünç Güneri","Alper Berke Yavuz","Mahmut Ali Gökçe","Cansu Yurtseven"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"d74b8c67a747ee925e2d38307b763f0b","permalink":"https://copuronur.github.io/publication/conference-paper1/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/conference-paper1/","section":"publication","summary":"Izmir based Information Technology (IT) solution provider develops supply chain management software tools for many customers from fast moving consumer goods sector (FMCG). Customers of the FMCG sector needs to be visited a certain number of times in a given period by sales representatives. The company must decide which customers must be visited in which sequence by each sales representative while obeying visit frequency and time windows requirements. These decisions have significant impact on total cost. For this reason, finding an optimal route for every sales representative for each day of the planning horizon is important. This practically challenging and technically important problem can be described as periodic multiple depot traveling salesman problem with time windows (PMDTSPTW). We propose a novel mathematical model for the optimal solution of this problem. The proposed model minimizes the total distance traveled by sales representatives by deciding which sales representative will visit which customer on which day while following the time windows to collect demand data. The proposed model is applicable to any company from FMCG sector. The solution approach in this study is implemented and tested with real life including coordinates and location data of customers and sales representatives from Turkey’s largest beer distributor. The proposed model is solved using IBM ILOG CPLEX Optimization Studio version 12.8. The results show significant improvement over the current situation. To ensure efficient usage of the proposed approach, a user-friendly decision support system (DSS) is constructed and implemented.","tags":null,"title":"Periodic Route Optimization for FMCG Distributors","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne \r**Two** \rThree \r A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://copuronur.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"0fb9fb6af67edb8a9408f748ea651461","permalink":"https://copuronur.github.io/project/emotion_recognition/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/emotion_recognition/","section":"project","summary":"Training a  CNN for emotion recognition and explaining the behaviour of the model.","tags":["Computer Vision"],"title":"Emotion Recognition CNN","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c8f52fb13233cea9a2487f8f4bcfb48c","permalink":"https://copuronur.github.io/project/engagement_detection/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/engagement_detection/","section":"project","summary":"An end-to-end deep learning-based system that detects the engagement level of the subject in an e-learning environment.","tags":["Computer Vision"],"title":"Engagement Detection with OpenFace \u0026 Bi-LSTM","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c581f1dec64e652d1e9fcd0a860f7b8b","permalink":"https://copuronur.github.io/project/nba-statistics/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/nba-statistics/","section":"project","summary":"3 main goals of this Project; Predicting the result of NBA games.Predicting the outcome of Field goal attempts of Lebron James..","tags":["Machine Learning"],"title":"NBA Statistics","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"0db46c53d6750c47eb8ee73b5315c150","permalink":"https://copuronur.github.io/project/svm/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/svm/","section":"project","summary":"Implementing the Support Vector Machine (SVM) from scratch for binary and multi label classification task.","tags":["Machine Learning"],"title":"SVM from Scratch","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://copuronur.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]